{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta, datetime\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "directory = 'D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/'\n",
    "font_path = directory + 'NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path, size=10).get_name()\n",
    "plt.rc('font', family=font_name, size=12)\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "dev_users_path ='D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/predict/predict/dev.users'\n",
    "dev_users_list = []\n",
    "with open(dev_users_path, 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "    dev_users_list = lines\n",
    "    del lines\n",
    "for i in range(len(dev_users_list)):\n",
    "    dev_users_list[i] = dev_users_list[i].replace('\\n','')\n",
    "    \n",
    "test_users_path ='D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/predict/predict/test.users'\n",
    "test_users_list = []\n",
    "with open(test_users_path, 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "    test_users_list = lines\n",
    "    del lines\n",
    "for i in range(len(test_users_list)):\n",
    "    test_users_list[i] = test_users_list[i].replace('\\n','')\n",
    "\n",
    "print(len(dev_users_list))\n",
    "print(len(test_users_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- FEB_top_30000 : 2월 1일 ~ 3월 1일 읽은 글 top 30000\n",
    "- TOTAL_top_30000 : 10월 1일 ~ 3월 1일까지 읽은 글 top 30000\n",
    "\n",
    "- FEB_top_58647 : 2월 14일 ~ 3월 1일간 읽은 글 best\n",
    "    \n",
    "- FEB_MAR_article : 2월 1일 ~ 3월 까지 등록된 글\n",
    "- FEB_MAR_article_2 : 2월 14일 ~ 3월 1일 등록된 글\n",
    "- MAR_article_1 : 3월 1일 ~ 3월 7일 등록된 글\n",
    "- MAR_article_2 : 3월 7일 ~ 3월 14일 등록된 글 \n",
    " *기간은 왼쪽 처음은 닫힌 구간, 오른쪽 끝은 열린 구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "44278\n",
      "30000\n",
      "20190723 update\n",
      "58648\n",
      "11641\n",
      "4654\n",
      "5322\n"
     ]
    }
   ],
   "source": [
    "FEB_top_58647 = pd.read_csv(directory+'FEB_top_58647.csv')\n",
    "FEB_top_58647 = FEB_top_58647.drop('Unnamed: 0',1)\n",
    "FEB_MAR_article_2 = pd.read_csv(directory+'FEB_MAR_article_2.csv')\n",
    "FEB_MAR_article_2 = FEB_MAR_article_2.drop('Unnamed: 0',1)\n",
    "MAR_article_1 = pd.read_csv(directory+'MAR_article_1.csv')\n",
    "MAR_article_1 = MAR_article_1.drop('Unnamed: 0',1)\n",
    "MAR_article_2 = pd.read_csv(directory+'MAR_article_2.csv')\n",
    "MAR_article_2 = MAR_article_2.drop('Unnamed: 0',1)\n",
    "\n",
    "print(len(FEB_top_30000))\n",
    "print(len(FEB_MAR_article))\n",
    "print(len(TOTAL_top_30000))\n",
    "\n",
    "print('20190723 update')\n",
    "print(len(FEB_top_58647))\n",
    "print(len(FEB_MAR_article_2)) # 이건 필요가 없을 수도 있겠다 어차피 안 팔릴 글은 안 읽었을테니\n",
    "print(len(MAR_article_1))\n",
    "print(len(MAR_article_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 읽은 글 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- article_seen_by_testuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory + 'article_by_testuser.json') as f:\n",
    "    article_seen_by_testuser = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## following list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_json(directory + '/users.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>following_list</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@perytail, @brunch]</td>\n",
       "      <td>#901985d8bc4c481805c4a4f911814c4a</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         following_list                                 id keyword_list\n",
       "0  [@perytail, @brunch]  #901985d8bc4c481805c4a4f911814c4a           []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "users_following_lists = [] \n",
    "for i in range(5000):\n",
    "    uid = test_users_list[i]\n",
    "    ufl = list(users[users['id'] == uid]['following_list'])\n",
    "    if len(ufl) > 0:\n",
    "        users_following_lists.append(ufl)\n",
    "    else:\n",
    "        users_following_lists.append([])\n",
    "print(time.time() - st , 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_following_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@avecrhae',\n",
       " '@gongdae-unni',\n",
       " '@jhcharm1',\n",
       " '@travel-heather',\n",
       " '@swimmingstar',\n",
       " '@1simforyou',\n",
       " '@alicemelbourne',\n",
       " '@2jaemyung',\n",
       " '@brunch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_following_lists[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- r2\n",
    "- author_lists\n",
    "- class_lists\n",
    "- magainze_lists\n",
    "- unique_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20190207 이후에 읽은 글들로 앞으로 읽을 글들을 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory + 'rasby_devuser_100.csv',encoding='utf-8') as f:\n",
    "    r1 = pd.read_csv(f)\n",
    "\n",
    "r1 = r1.drop('Unnamed: 0',1)\n",
    "r1['read_dt']  = r1['read_dt'].map(lambda x : x.replace('-',''))\n",
    "a = '20190207' # 이것도 hyp \n",
    "r2 = r1[r1['read_dt'] >= a]\n",
    "\n",
    "def int_class(x):\n",
    "    if x == '5%':\n",
    "        result = 5\n",
    "    elif x == '10%':\n",
    "        result = 10\n",
    "    elif x == '25%':\n",
    "        result = 25\n",
    "    elif x == '50%':\n",
    "        result = 50\n",
    "    elif x == '75%':\n",
    "        result = 75\n",
    "    else:\n",
    "        result = 100\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_dt</th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>reg_dt</th>\n",
       "      <th>type</th>\n",
       "      <th>display_url</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>off_day</th>\n",
       "      <th>read_cnt</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190212</td>\n",
       "      <td>#d6866a498157771069fdf15361cb012b</td>\n",
       "      <td>@april_78</td>\n",
       "      <td>주택청약, 저는 언제쯤 제 집을...?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@april</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>매거진</td>\n",
       "      <td>https://brunch.co.kr/@april/78</td>\n",
       "      <td>['주택청약통장', '주택청약', '청약통장']</td>\n",
       "      <td>42262.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190212</td>\n",
       "      <td>#d6866a498157771069fdf15361cb012b</td>\n",
       "      <td>@noonsil_12</td>\n",
       "      <td>틀린 게 아니고 다른 겁니다.</td>\n",
       "      <td>주부의 눈으로 본 태국이 다른 점</td>\n",
       "      <td>@noonsil</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>매거진</td>\n",
       "      <td>https://brunch.co.kr/@noonsil/12</td>\n",
       "      <td>['에어비앤비', '치앙마이', '파타야']</td>\n",
       "      <td>42485.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    read_dt                            user_id   article_id  \\\n",
       "0  20190212  #d6866a498157771069fdf15361cb012b    @april_78   \n",
       "1  20190212  #d6866a498157771069fdf15361cb012b  @noonsil_12   \n",
       "\n",
       "                   title           sub_title author_id      reg_dt type  \\\n",
       "0  주택청약, 저는 언제쯤 제 집을...?                 NaN    @april  2019-02-06  매거진   \n",
       "1       틀린 게 아니고 다른 겁니다.  주부의 눈으로 본 태국이 다른 점  @noonsil  2019-02-08  매거진   \n",
       "\n",
       "                        display_url                keyword_list  magazine_id  \\\n",
       "0    https://brunch.co.kr/@april/78  ['주택청약통장', '주택청약', '청약통장']      42262.0   \n",
       "1  https://brunch.co.kr/@noonsil/12    ['에어비앤비', '치앙마이', '파타야']      42485.0   \n",
       "\n",
       "   off_day  read_cnt class  \n",
       "0      6.0     300.0    5%  \n",
       "1      4.0     703.0    5%  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 중복소비가 20건\n",
    "# 평가 데이터에는 중복 소비가 없음\n",
    "# 따라서 중복 소비 제거하고 최신 동향으로 추천하는 식 ㄱㄱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:06<00:00, 45.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# 읽은 구독자 list 도 만들기\n",
    "# 개인 or magazine\n",
    "# 이부분은 나중에 test_users_list , 5000 , test_user에 맞게 수정해주어야함\n",
    "author_lists = []\n",
    "class_lists = []\n",
    "magazine_lists = []\n",
    "unique_author = []\n",
    "for i in tqdm(range(3000),mininterval = 1): ### final 시 수정\n",
    "    recent_read_raw = r2[r2['user_id'] == dev_users_list[i]]  \n",
    "    recent_read_raw = recent_read_raw.sort_values(by = ['read_dt'],ascending = False)\n",
    "    recent_read_raw = recent_read_raw.drop_duplicates(['article_id'])\n",
    "    \n",
    "    len_recent_read_raw = len(recent_read_raw)\n",
    "    \n",
    "    # class mean\n",
    "    class_sum = 0\n",
    "    magazine_sum = 0\n",
    "    # 최신에 읽은 작가들 정보 모으기\n",
    "    author_list = []\n",
    "    author_cnt = []\n",
    "    for j in range(len_recent_read_raw):\n",
    "        # class mean\n",
    "        rrr = recent_read_raw[j:j+1]\n",
    "        class_int = int_class(list(rrr['class'])[0])\n",
    "        class_sum += class_int\n",
    "        # magainze mean\n",
    "        magazine_type = list(rrr['type'])[0]\n",
    "        if(magazine_type == '매거진'):\n",
    "            magazine_sum += 1\n",
    "        # author list\n",
    "        author = list(rrr['author_id'])[0]\n",
    "        found = 0\n",
    "        for k in range(len(author_list)):\n",
    "            if author_list[k] == author:\n",
    "                author_cnt[k] += 1\n",
    "                found = 1\n",
    "                break\n",
    "        if(found == 0):\n",
    "            author_list.append(author)\n",
    "            author_cnt.append(1)\n",
    "\n",
    "    author_list_dict = dict()\n",
    "    for j in range(len(author_list)):\n",
    "        author_list_dict[author_list[j]] = author_cnt[j]\n",
    "\n",
    "    if(len_recent_read_raw != 0 ):\n",
    "        class_mean = class_sum / len_recent_read_raw\n",
    "        class_lists.append(class_mean)\n",
    "        \n",
    "        magazine_mean = magazine_sum / len_recent_read_raw\n",
    "        magazine_lists.append(magazine_mean)\n",
    "        \n",
    "        #author_list_dict = sorted(author_list_dict.items(), key=(lambda x: x[1]), reverse = True) # 이러면 [ (), () ]형태\n",
    "        author_lists.append(author_list_dict)\n",
    "        \n",
    "        unique_author.append(len(author_list))\n",
    "    else:\n",
    "        class_lists.append(5.0)\n",
    "        magazine_lists.append(1.0)\n",
    "        author_lists.append(dict())\n",
    "        unique_author.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 얘네들 키 안 맞음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신에 읽은 글들에서 구독자들이 있는지 확인\n",
    "# 없는 구독자는 이때까지 읽은 글을 검사해서 최신 동향이 아닌 구독자는 빼면 더 좋을 듯 하긴하네\n",
    "diff_fa = []\n",
    "diff_cnt = 0\n",
    "for i in range(3000):\n",
    "    keys = set(list(author_lists[i].keys()))\n",
    "    for j in range(5000):\n",
    "        if uid == test_users_list[j]:\n",
    "            i = j\n",
    "            break\n",
    "    if len(users_following_lists[i]) > 0:\n",
    "        following_author = set(users_following_lists[i][0])\n",
    "    else :\n",
    "        following_author = set()\n",
    "    diff_fa = list(following_author - keys)\n",
    "    diff_cnt += len(diff_fa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.612"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_cnt / 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "following_author_cnt = 0\n",
    "for i in range(3000):\n",
    "    if len(users_following_lists[i]) > 0:\n",
    "        following_author_cnt += len(users_following_lists[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.88233333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "following_author_cnt /3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_lists \n",
    "class_lists \n",
    "magazine_lists \n",
    "unique_author "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIM 기존 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134994\n",
      "505842\n",
      "134994\n"
     ]
    }
   ],
   "source": [
    "article_similarity = np.load(directory+'article_similarity_t.npy')\n",
    "article_similarity = article_similarity.tolist()\n",
    "with open(directory + 'word_to_id.json') as f:\n",
    "    word_to_id  = json.load(f)\n",
    "\n",
    "with open(directory + 'id_to_word.json') as f:\n",
    "    id_to_word = json.load(f)\n",
    "\n",
    "print(len(article_similarity))\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIM 업데이트 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165110\n",
      "486427\n",
      "165110\n"
     ]
    }
   ],
   "source": [
    "article_similarity = np.load(directory+'article_similarity_recent_t.npy')\n",
    "article_similarity = article_similarity.tolist()\n",
    "with open(directory + 'word_to_id_recent.json') as f:\n",
    "    word_to_id  = json.load(f)\n",
    "\n",
    "with open(directory + 'id_to_word_recent.json') as f:\n",
    "    id_to_word = json.load(f)\n",
    "\n",
    "print(len(article_similarity))\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEB_top_58647_list = FEB_top_58647['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@seungyae613_22', '@namgizaa_46', '@connerstoneiqvk_26']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = article_seen_by_testuser[str(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = article_seen_by_testuser[str(0)]\n",
    "r = list(reversed(r))\n",
    "s = []\n",
    "for a in range(len(r)):\n",
    "    if r[a] not in s:\n",
    "        s.append(r[a])\n",
    "r = list(reversed(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)\n",
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = article_seen_by_testuser[str(i)]\n",
    "        \n",
    "# 읽은 아티클에서 중복 제거할떄도 최신의 글이 살아남게끔 제거해야한다\n",
    "s = []\n",
    "for a in range(len(r)):\n",
    "    if r[a] not in s:\n",
    "        s.append(r[a])\n",
    "r = s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 좀더 신중히 다뤄 보도록 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>read_cnt</th>\n",
       "      <th>id</th>\n",
       "      <th>display_url</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>reg_datetime</th>\n",
       "      <th>reg_dt</th>\n",
       "      <th>type</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30410</th>\n",
       "      <td>@dooook_141</td>\n",
       "      <td>10</td>\n",
       "      <td>141.0</td>\n",
       "      <td>https://brunch.co.kr/@dooook/141</td>\n",
       "      <td>['메신저', '왓츠앱', '카카오톡']</td>\n",
       "      <td>19396.0</td>\n",
       "      <td>1.547551e+12</td>\n",
       "      <td>글로벌 메신저 '왓츠앱'과 한국의 국민 메신저 '카카오톡'</td>\n",
       "      <td>글로벌한 시각은 글로벌한 경험에서 나온다</td>\n",
       "      <td>@dooook</td>\n",
       "      <td>2019-01-15 20:09:50</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30411</th>\n",
       "      <td>@lunar611_7</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>https://brunch.co.kr/@lunar611/7</td>\n",
       "      <td>['작가지망생', '아르바이트', '친구']</td>\n",
       "      <td>41194.0</td>\n",
       "      <td>1.547053e+12</td>\n",
       "      <td>당신을 묵묵히 응원해줄 단 한 사람</td>\n",
       "      <td>6. 지망생의 여행가방에 꼭 넣어야 할 것들 (2)</td>\n",
       "      <td>@lunar611</td>\n",
       "      <td>2019-01-10 01:49:17</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30412</th>\n",
       "      <td>@zzyoun_46</td>\n",
       "      <td>10</td>\n",
       "      <td>46.0</td>\n",
       "      <td>https://brunch.co.kr/@zzyoun/46</td>\n",
       "      <td>['영화', '택시운전사', '송강호']</td>\n",
       "      <td>20709.0</td>\n",
       "      <td>1.507544e+12</td>\n",
       "      <td>&lt;택시운전사&gt;</td>\n",
       "      <td>직업윤리와 나비효과</td>\n",
       "      <td>@zzyoun</td>\n",
       "      <td>2017-10-09 19:21:23</td>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30413</th>\n",
       "      <td>@honeytip_1109</td>\n",
       "      <td>10</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>https://brunch.co.kr/@honeytip/1109</td>\n",
       "      <td>['맛집', '강릉', '여행']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.540627e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>강릉 여행에서 꼭 가봐야 할 유명 맛집 6곳</td>\n",
       "      <td>@honeytip</td>\n",
       "      <td>2018-10-27 16:48:55</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>개인</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30414</th>\n",
       "      <td>@hosungsong_380</td>\n",
       "      <td>10</td>\n",
       "      <td>380.0</td>\n",
       "      <td>https://brunch.co.kr/@hosungsong/380</td>\n",
       "      <td>['사진', '웨딩스튜디오추천']</td>\n",
       "      <td>37837.0</td>\n",
       "      <td>1.546064e+12</td>\n",
       "      <td>사람</td>\n",
       "      <td>#18</td>\n",
       "      <td>@hosungsong</td>\n",
       "      <td>2018-12-29 15:18:06</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30415</th>\n",
       "      <td>@jjacksarang_61</td>\n",
       "      <td>10</td>\n",
       "      <td>61.0</td>\n",
       "      <td>https://brunch.co.kr/@jjacksarang/61</td>\n",
       "      <td>['이별', '사랑', '연애']</td>\n",
       "      <td>25672.0</td>\n",
       "      <td>1.513382e+12</td>\n",
       "      <td>내가 아는 '그'의 이야기</td>\n",
       "      <td>착함 콤플렉스</td>\n",
       "      <td>@jjacksarang</td>\n",
       "      <td>2017-12-16 08:48:17</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30416</th>\n",
       "      <td>@jacobsfoto_125</td>\n",
       "      <td>10</td>\n",
       "      <td>125.0</td>\n",
       "      <td>https://brunch.co.kr/@jacobsfoto/125</td>\n",
       "      <td>['사진', '사랑', '이별']</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>1.546701e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>가치있어서가 아니라 같이있어서</td>\n",
       "      <td>@jacobsfoto</td>\n",
       "      <td>2019-01-06 00:04:04</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30417</th>\n",
       "      <td>@hotaro_10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>https://brunch.co.kr/@hotaro/10</td>\n",
       "      <td>['온라인쇼핑몰', '쇼핑몰', '시크헤라']</td>\n",
       "      <td>38301.0</td>\n",
       "      <td>1.540639e+12</td>\n",
       "      <td>3세대 쇼핑몰의 빅데이터 전략 엿보기</td>\n",
       "      <td>온라인쇼핑몰 '시크헤라' 인터뷰</td>\n",
       "      <td>@hotaro</td>\n",
       "      <td>2018-10-27 20:19:26</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30418</th>\n",
       "      <td>@movemovemove_24</td>\n",
       "      <td>10</td>\n",
       "      <td>24.0</td>\n",
       "      <td>https://brunch.co.kr/@movemovemove/24</td>\n",
       "      <td>['세계여행', '여행', '남미']</td>\n",
       "      <td>12170.0</td>\n",
       "      <td>1.495759e+12</td>\n",
       "      <td>남미 그리고 다시 북미로</td>\n",
       "      <td>세계여행 9개월, 3/4분기 정산</td>\n",
       "      <td>@movemovemove</td>\n",
       "      <td>2017-05-26 09:38:17</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30419</th>\n",
       "      <td>@ccantare_2</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>https://brunch.co.kr/@ccantare/2</td>\n",
       "      <td>['그림일기', '애니메이션', '가족']</td>\n",
       "      <td>43107.0</td>\n",
       "      <td>1.550302e+12</td>\n",
       "      <td>시작합니다!</td>\n",
       "      <td>#1   시작합니다~</td>\n",
       "      <td>@ccantare</td>\n",
       "      <td>2019-02-16 16:24:34</td>\n",
       "      <td>2019-02-16</td>\n",
       "      <td>매거진</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_id read_cnt      id  \\\n",
       "30410       @dooook_141       10   141.0   \n",
       "30411       @lunar611_7       10     7.0   \n",
       "30412        @zzyoun_46       10    46.0   \n",
       "30413    @honeytip_1109       10  1109.0   \n",
       "30414   @hosungsong_380       10   380.0   \n",
       "30415   @jjacksarang_61       10    61.0   \n",
       "30416   @jacobsfoto_125       10   125.0   \n",
       "30417        @hotaro_10       10    10.0   \n",
       "30418  @movemovemove_24       10    24.0   \n",
       "30419       @ccantare_2        9     2.0   \n",
       "\n",
       "                                 display_url               keyword_list  \\\n",
       "30410       https://brunch.co.kr/@dooook/141     ['메신저', '왓츠앱', '카카오톡']   \n",
       "30411       https://brunch.co.kr/@lunar611/7   ['작가지망생', '아르바이트', '친구']   \n",
       "30412        https://brunch.co.kr/@zzyoun/46     ['영화', '택시운전사', '송강호']   \n",
       "30413    https://brunch.co.kr/@honeytip/1109         ['맛집', '강릉', '여행']   \n",
       "30414   https://brunch.co.kr/@hosungsong/380         ['사진', '웨딩스튜디오추천']   \n",
       "30415   https://brunch.co.kr/@jjacksarang/61         ['이별', '사랑', '연애']   \n",
       "30416   https://brunch.co.kr/@jacobsfoto/125         ['사진', '사랑', '이별']   \n",
       "30417        https://brunch.co.kr/@hotaro/10  ['온라인쇼핑몰', '쇼핑몰', '시크헤라']   \n",
       "30418  https://brunch.co.kr/@movemovemove/24       ['세계여행', '여행', '남미']   \n",
       "30419       https://brunch.co.kr/@ccantare/2    ['그림일기', '애니메이션', '가족']   \n",
       "\n",
       "       magazine_id        reg_ts                         sub_title  \\\n",
       "30410      19396.0  1.547551e+12  글로벌 메신저 '왓츠앱'과 한국의 국민 메신저 '카카오톡'   \n",
       "30411      41194.0  1.547053e+12               당신을 묵묵히 응원해줄 단 한 사람   \n",
       "30412      20709.0  1.507544e+12                           <택시운전사>   \n",
       "30413          0.0  1.540627e+12                               NaN   \n",
       "30414      37837.0  1.546064e+12                                사람   \n",
       "30415      25672.0  1.513382e+12                    내가 아는 '그'의 이야기   \n",
       "30416       3493.0  1.546701e+12                               NaN   \n",
       "30417      38301.0  1.540639e+12              3세대 쇼핑몰의 빅데이터 전략 엿보기   \n",
       "30418      12170.0  1.495759e+12                     남미 그리고 다시 북미로   \n",
       "30419      43107.0  1.550302e+12                            시작합니다!   \n",
       "\n",
       "                              title      author_id         reg_datetime  \\\n",
       "30410        글로벌한 시각은 글로벌한 경험에서 나온다        @dooook  2019-01-15 20:09:50   \n",
       "30411  6. 지망생의 여행가방에 꼭 넣어야 할 것들 (2)      @lunar611  2019-01-10 01:49:17   \n",
       "30412                    직업윤리와 나비효과        @zzyoun  2017-10-09 19:21:23   \n",
       "30413      강릉 여행에서 꼭 가봐야 할 유명 맛집 6곳      @honeytip  2018-10-27 16:48:55   \n",
       "30414                           #18    @hosungsong  2018-12-29 15:18:06   \n",
       "30415                       착함 콤플렉스   @jjacksarang  2017-12-16 08:48:17   \n",
       "30416              가치있어서가 아니라 같이있어서    @jacobsfoto  2019-01-06 00:04:04   \n",
       "30417             온라인쇼핑몰 '시크헤라' 인터뷰        @hotaro  2018-10-27 20:19:26   \n",
       "30418            세계여행 9개월, 3/4분기 정산  @movemovemove  2017-05-26 09:38:17   \n",
       "30419                   #1   시작합니다~      @ccantare  2019-02-16 16:24:34   \n",
       "\n",
       "           reg_dt type class  \n",
       "30410  2019-01-15  매거진   50%  \n",
       "30411  2019-01-10  매거진   50%  \n",
       "30412  2017-10-09  매거진   50%  \n",
       "30413  2018-10-27   개인   50%  \n",
       "30414  2018-12-29  매거진   50%  \n",
       "30415  2017-12-16  매거진   50%  \n",
       "30416  2019-01-06  매거진   50%  \n",
       "30417  2018-10-27  매거진   50%  \n",
       "30418  2017-05-26  매거진   50%  \n",
       "30419  2019-02-16  매거진   50%  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEB_top_58647[30410:30420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEB_top_30419 , 비교 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_cnt >= 10 만 자른것\n",
    "FEB_top_30419 = FEB_top_58647[:30419]\n",
    "FEB_top_30419_list = FEB_top_30419['article_id'].tolist()\n",
    "len(FEB_top_30419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 가장 베스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/3000 [00:00<?, ?it/s]\n",
      "  2%|█▋                                                                              | 64/3000 [00:10<07:52,  6.21it/s]\n",
      "  4%|███▎                                                                           | 127/3000 [00:21<07:56,  6.03it/s]\n",
      "  7%|█████▎                                                                         | 201/3000 [00:31<07:19,  6.36it/s]\n",
      "  9%|███████▏                                                                       | 274/3000 [00:43<07:14,  6.28it/s]\n",
      " 11%|████████▊                                                                      | 335/3000 [00:54<07:14,  6.14it/s]\n",
      " 13%|██████████▍                                                                    | 397/3000 [01:04<07:05,  6.12it/s]\n",
      " 15%|████████████                                                                   | 458/3000 [01:15<07:10,  5.91it/s]\n",
      " 17%|█████████████▊                                                                 | 523/3000 [01:25<06:50,  6.04it/s]\n",
      " 20%|███████████████▍                                                               | 587/3000 [01:36<06:44,  5.96it/s]\n",
      " 22%|█████████████████▏                                                             | 655/3000 [01:46<06:21,  6.15it/s]\n",
      " 22%|█████████████████▏                                                             | 655/3000 [01:57<06:21,  6.15it/s]\n",
      " 24%|██████████████████▊                                                            | 713/3000 [01:57<06:23,  5.96it/s]\n",
      " 24%|██████████████████▊                                                            | 713/3000 [02:07<06:23,  5.96it/s]\n",
      " 26%|████████████████████▎                                                          | 770/3000 [02:07<06:19,  5.87it/s]\n",
      " 28%|█████████████████████▊                                                         | 829/3000 [02:17<06:09,  5.88it/s]\n",
      " 28%|█████████████████████▊                                                         | 829/3000 [02:27<06:09,  5.88it/s]\n",
      " 29%|███████████████████████▎                                                       | 883/3000 [02:27<06:11,  5.69it/s]\n",
      " 29%|███████████████████████▎                                                       | 883/3000 [02:37<06:11,  5.69it/s]\n",
      " 31%|████████████████████████▊                                                      | 940/3000 [02:37<06:04,  5.65it/s]\n",
      " 33%|██████████████████████████                                                    | 1004/3000 [02:47<05:41,  5.85it/s]\n",
      " 36%|███████████████████████████▊                                                  | 1068/3000 [02:58<05:29,  5.87it/s]\n",
      " 38%|█████████████████████████████▎                                                | 1128/3000 [03:09<05:26,  5.73it/s]\n",
      " 39%|██████████████████████████████▊                                               | 1183/3000 [03:19<05:21,  5.65it/s]\n",
      " 42%|████████████████████████████████▍                                             | 1247/3000 [03:29<05:00,  5.83it/s]\n",
      " 44%|██████████████████████████████████                                            | 1311/3000 [03:40<04:43,  5.95it/s]\n",
      " 46%|███████████████████████████████████▉                                          | 1380/3000 [03:50<04:21,  6.20it/s]\n",
      " 48%|█████████████████████████████████████▋                                        | 1449/3000 [04:02<04:14,  6.08it/s]\n",
      " 50%|███████████████████████████████████████▏                                      | 1508/3000 [04:13<04:16,  5.81it/s]\n",
      " 52%|████████████████████████████████████████▊                                     | 1569/3000 [04:23<04:02,  5.89it/s]\n",
      " 54%|██████████████████████████████████████████▍                                   | 1630/3000 [04:34<03:57,  5.76it/s]\n",
      " 57%|████████████████████████████████████████████                                  | 1696/3000 [04:44<03:38,  5.98it/s]\n",
      " 59%|█████████████████████████████████████████████▊                                | 1762/3000 [04:55<03:28,  5.94it/s]\n",
      " 61%|███████████████████████████████████████████████▍                              | 1826/3000 [05:05<03:14,  6.04it/s]\n",
      " 63%|█████████████████████████████████████████████████                             | 1889/3000 [05:15<03:01,  6.11it/s]\n",
      " 65%|██████████████████████████████████████████████████▊                           | 1954/3000 [05:26<02:48,  6.21it/s]\n",
      " 67%|████████████████████████████████████████████████████▍                         | 2019/3000 [05:36<02:38,  6.18it/s]\n",
      " 70%|██████████████████████████████████████████████████████▎                       | 2089/3000 [05:46<02:22,  6.38it/s]\n",
      " 72%|████████████████████████████████████████████████████████                      | 2158/3000 [05:57<02:12,  6.34it/s]\n",
      " 72%|████████████████████████████████████████████████████████                      | 2158/3000 [05:57<02:12,  6.34it/s]\n",
      " 74%|█████████████████████████████████████████████████████████▊                    | 2225/3000 [06:07<02:00,  6.42it/s]\n",
      " 74%|█████████████████████████████████████████████████████████▊                    | 2225/3000 [06:07<02:00,  6.42it/s]\n",
      " 76%|███████████████████████████████████████████████████████████▏                  | 2278/3000 [06:18<01:59,  6.03it/s]\n",
      " 76%|███████████████████████████████████████████████████████████▏                  | 2278/3000 [06:18<01:59,  6.03it/s]\n",
      " 76%|███████████████████████████████████████████████████████████▏                  | 2278/3000 [06:28<01:59,  6.03it/s]\n",
      " 78%|████████████████████████████████████████████████████████████▋                 | 2333/3000 [06:28<01:54,  5.84it/s]\n",
      " 78%|████████████████████████████████████████████████████████████▋                 | 2333/3000 [06:38<01:54,  5.84it/s]\n",
      " 80%|██████████████████████████████████████████████████████████████                | 2389/3000 [06:38<01:46,  5.72it/s]\n",
      " 82%|███████████████████████████████████████████████████████████████▋              | 2451/3000 [06:48<01:34,  5.83it/s]\n",
      " 84%|█████████████████████████████████████████████████████████████████▎            | 2513/3000 [06:59<01:24,  5.79it/s]\n",
      " 86%|██████████████████████████████████████████████████████████████████▉           | 2575/3000 [07:09<01:12,  5.90it/s]\n",
      " 88%|████████████████████████████████████████████████████████████████████▌         | 2637/3000 [07:19<01:01,  5.93it/s]\n",
      " 90%|██████████████████████████████████████████████████████████████████████        | 2697/3000 [07:30<00:51,  5.86it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████████████▋      | 2759/3000 [07:40<00:40,  5.94it/s]\n",
      " 94%|█████████████████████████████████████████████████████████████████████████▎    | 2821/3000 [07:50<00:30,  5.94it/s]\n",
      " 96%|██████████████████████████████████████████████████████████████████████████▉   | 2881/3000 [08:01<00:20,  5.79it/s]\n",
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 2950/3000 [08:12<00:08,  6.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [08:20<00:00,  5.99it/s]"
     ]
    }
   ],
   "source": [
    "#hyper parameter\n",
    "hyp_author = 100\n",
    "hyp_recent_article_len = 10\n",
    "hyp_top_k = 10\n",
    "hyp_read_cnt = 10\n",
    "hyp_sim = 80\n",
    "\n",
    "isdev = 1\n",
    "\n",
    "hyp = str(hyp_author) + '_' +str(hyp_recent_article_len)+'_'+str(hyp_top_k)+'_'+ str(hyp_read_cnt)+'_'+str(hyp_sim)+'_'+'DEV_FINAL'\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(directory + hyp )):\n",
    "        os.makedirs(os.path.join(directory + hyp))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise\n",
    "            \n",
    "countt = 0\n",
    "cntttt = 0\n",
    "\n",
    "ral = []\n",
    "siml = []\n",
    "tol = []\n",
    "ulfs = []\n",
    "tol2 = []\n",
    "with open(directory + hyp +'/recommend' + '.txt','w') as file:\n",
    "    for i in tqdm(range(len(dev_users_list)),mininterval=10):\n",
    "        \n",
    "        recommend_all=[]\n",
    "        uid = dev_users_list[i]\n",
    "        aid = i # author index \n",
    "        \n",
    "        for j in range(5000):\n",
    "            if uid == test_users_list[j]:\n",
    "                i = j\n",
    "                break\n",
    "        \n",
    "        # 현재 유저가 읽은 following list\n",
    "        ufl = users_following_lists[i]\n",
    "        if(len(ufl) > 0):\n",
    "            ufl  = ufl[0]\n",
    "            \n",
    "        # 현재 유저가 읽은 모든 글 , \n",
    "        r = article_seen_by_testuser[str(i)]\n",
    "        # 최신에 읽은 글들이 사라지지 않게 뒤집고 중복 제거하기\n",
    "        r = list(reversed(r))\n",
    "        s = []\n",
    "        \n",
    "        for a in range(len(r)):\n",
    "            if r[a] not in s:\n",
    "                s.append(r[a])\n",
    "        r = list(reversed(s))\n",
    "\n",
    "        # 최신 읽은 작가 정보를 업데이트\n",
    "        # type(author_and_cnt) = dict 임\n",
    "        author_and_cnt = author_lists[aid]\n",
    "        if hyp_author > 0:\n",
    "            \n",
    "            # 일단 recent 2주 top 58647 에서\n",
    "            recommend_author = []\n",
    "            cnt_author = 0            \n",
    "            author_consider_set = set()\n",
    "            \n",
    "            for key, value in author_and_cnt.items(): #이거를 3개 만들어서 하는 게 NDCG 높이는데 기여할듯\n",
    "                author = key\n",
    "                cnt = value\n",
    "                author_consider_set.add(key)\n",
    "                # 2월 14일 ~ 3월 1일간 인기글 30419개 중에 있으면 뽑기\n",
    "                author_all_article_1 = FEB_top_30419[FEB_top_30419['author_id'] == author].sort_values(by='reg_dt',ascending=False) # 최신에 작성한 글들의 인기순이겠지 # 더 줄여봐도 될 듯\n",
    "                cnt_1 = 0\n",
    "                for j in range(len(author_all_article_1)):\n",
    "                    if(cnt_1 >= cnt): break\n",
    "                    artic = list(author_all_article_1[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_author:\n",
    "                            recommend_author.append(artic)\n",
    "                            cnt_1 +=1\n",
    "                \n",
    "                #  3월 1일 ~ 3월 7일에 쓰여진 글 있으면 append\n",
    "                author_all_article_2 = MAR_article_1[MAR_article_1['author_id'] == author]\n",
    "                cnt_2 = 0\n",
    "                for j in range(len(author_all_article_2)):\n",
    "                    if(cnt_2 >= cnt): break\n",
    "                    artic = list(author_all_article_2[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_author:\n",
    "                            recommend_author.append(artic)\n",
    "                            cnt_2 +=1\n",
    "                            \n",
    "                #  3월 7일 ~ 3월 14일에 쓰여진 글 있으면 append\n",
    "                author_all_article_3 = MAR_article_2[MAR_article_2['author_id'] == author]\n",
    "                cnt_3 = 0\n",
    "                for j in range(len(author_all_article_3)):\n",
    "                    if(cnt_3 >= cnt): break\n",
    "                    artic = list(author_all_article_3[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_author:\n",
    "                            recommend_author.append(artic)\n",
    "                            cnt_3 +=1\n",
    "                \n",
    "            \n",
    "            # 100 개 이상 추천될 수 있으니 자르기 | hyper parameter 만큼 자르기\n",
    "            recommend_author = recommend_author[:hyp_author] # 체크\n",
    "            ral.append(len(recommend_author))\n",
    "            for artic in recommend_author:\n",
    "                if artic not in recommend_all:\n",
    "                    recommend_all.append(artic)\n",
    "            \n",
    "        # 구독자를 먼저 넣어보자\n",
    "        # recent때 활용하지 않은 구독자 정보를 이용한다\n",
    "        ufl_not_yet = []\n",
    "        for t in range(len(ufl)):\n",
    "            if ufl[t] not in author_consider_set:\n",
    "                ufl_not_yet.append(ufl[t])\n",
    "\n",
    "        ufls_i = 0\n",
    "        if len(ufl_not_yet) > 0:\n",
    "\n",
    "            for author in ufl_not_yet: # 여기도 제일 많이 읽은 작가 순으로 넣어주는게 바람직하겠지?\n",
    "                if(len(recommend_all) >= 100): break\n",
    "                author_all_article_1 = FEB_top_30419[FEB_top_30419['author_id'] == author].sort_values(by='reg_dt',ascending=False) # top 50000 or to 10000 으로 바꿔서 비\n",
    "\n",
    "                cnt_1 = 0\n",
    "                for j in range(len(author_all_article_1)):\n",
    "                    if(len(recommend_all) >= 80): break #이것도 조정 필요\n",
    "\n",
    "                    artic = list(author_all_article_1[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_all:\n",
    "                            recommend_all.append(artic)\n",
    "                            cnt_1 +=1\n",
    "                            ufls_i+=1\n",
    "\n",
    "\n",
    "                #  3월 1일 ~ 3월 7일에 쓰여진 글 있으면 append\n",
    "\n",
    "                author_all_article_2 = MAR_article_1[MAR_article_1['author_id'] == author]\n",
    "                cnt_2 = 0\n",
    "                for j in range(len(author_all_article_2)):\n",
    "                    if(len(recommend_all) >= 90): break #얘도 조정 필요하고\n",
    "                    artic = list(author_all_article_2[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_all:\n",
    "                            recommend_all.append(artic)\n",
    "                            cnt_2 +=1\n",
    "                            ufls_i+=1\n",
    "\n",
    "                #  3월 7일 ~ 3월 14일에 쓰여진 글 있으면 append\n",
    "                author_all_article_3 = MAR_article_2[MAR_article_2['author_id'] == author]\n",
    "                cnt_3 = 0\n",
    "                for j in range(len(author_all_article_3)):\n",
    "                    if(len(recommend_all) >= 100): break #얘는 그대로 뭐 둬도 (entropy가 높지 않으면 바로 아래 걸로)\n",
    "                    artic = list(author_all_article_3[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_all:\n",
    "                            recommend_all.append(artic)\n",
    "                            cnt_3 +=1\n",
    "                            ufls_i+=1\n",
    "        tol.append(len(recommend_all))\n",
    "        \n",
    "        # 최신에 본 글 위주로 similarity 조사\n",
    "        if(len(r) >= hyp_read_cnt):\n",
    "            wtil = list(word_to_id.keys())\n",
    "            countt +=1\n",
    "            if(hyp_recent_article_len > len(r)):\n",
    "                hyp_recent_article_len = len(r)\n",
    "            r = r[-hyp_recent_article_len:]\n",
    "            r = list(reversed(r))\n",
    "            siml_cnt = 0\n",
    "            for j in range(len(r)):\n",
    "                if(siml_cnt>= hyp_sim): break\n",
    "                if(r[j] not in wtil):\n",
    "                    r[j] = 'UNK'\n",
    "                s = article_similarity[word_to_id[r[j]]]\n",
    "                sim_list = s[:hyp_top_k]\n",
    "                for k in range(len(sim_list)):\n",
    "                    if sim_list[k] not in recommend_all:\n",
    "                        recommend_all.append(sim_list[k])\n",
    "                        siml_cnt+=1\n",
    "                        if(siml_cnt>= hyp_sim): break\n",
    "            siml.append(siml_cnt)\n",
    "            if len(recommend_all)>=100:\n",
    "                recommend_all = recommend_all[:100]\n",
    "        \n",
    "        \n",
    "        tol2.append(len(recommend_all))\n",
    "        \n",
    "        if(len(recommend_all) >= 100):\n",
    "            recommend_all = recommend_all[:100]\n",
    "        else:\n",
    "            # 남으면 FEB_top 중 아무거나 뽑아서 주고\n",
    "            # following list 있으면 여기에 활용해도 좋을듯\n",
    "            cntttt+=1\n",
    "            \n",
    "                    \n",
    "            for x in FEB_top_30419_list:\n",
    "                if x not in recommend_all:\n",
    "                    recommend_all.append(x)\n",
    "                    if(len(recommend_all) == 100): break\n",
    "                        \n",
    "        # 다시 한 번 더 점검\n",
    "        if(len(recommend_all) > 100):\n",
    "            recommend_all = recommend_all[:100]\n",
    "        \n",
    "\n",
    "        recommend_normal = ''\n",
    "        for x in recommend_all:\n",
    "            recommend_normal += ' '+ x\n",
    "\n",
    "        file.write(uid + recommend_normal)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.34133333333333\n",
      "76.28275067230119\n",
      "82.17266666666667\n",
      "95.77\n",
      "478\n"
     ]
    }
   ],
   "source": [
    "print(sum(ral)/3000)\n",
    "print(sum(siml)/len(siml))\n",
    "print(sum(tol)/3000)\n",
    "print(sum(tol2)/3000)\n",
    "print(cntttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.071237\t0.166344\t9.024134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ral = author 로 추천된 아티클 수\n",
    "- siml = similarity 로 추천된 아티클 수\n",
    "- tol = 두개 합쳐서 전체 추천된 아티클 수\n",
    "- cntttt = else 에 걸리는 부분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 해볼 것들\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/3000 [00:00<?, ?it/s]\n",
      "  2%|█▎                                                                              | 47/3000 [00:10<10:28,  4.70it/s]\n",
      "  2%|█▎                                                                              | 47/3000 [00:21<10:28,  4.70it/s]\n",
      "  3%|██▍                                                                             | 90/3000 [00:21<11:15,  4.31it/s]\n",
      "  5%|███▊                                                                           | 144/3000 [00:32<10:25,  4.57it/s]"
     ]
    }
   ],
   "source": [
    "#hyper parameter\n",
    "hyp_author = 100\n",
    "hyp_recent_article_len = 10\n",
    "hyp_top_k = 10\n",
    "hyp_read_cnt = 10\n",
    "hyp_sim = 80\n",
    "\n",
    "isdev = 1\n",
    "\n",
    "hyp = str(hyp_author) + '_' +str(hyp_recent_article_len)+'_'+str(hyp_top_k)+'_'+ str(hyp_read_cnt)+'_'+str(hyp_sim)+'_'+'DEV_FINAL_58647'\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(directory + hyp )):\n",
    "        os.makedirs(os.path.join(directory + hyp))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise\n",
    "            \n",
    "countt = 0\n",
    "cntttt = 0\n",
    "\n",
    "ral = []\n",
    "siml = []\n",
    "tol = []\n",
    "ulfs = []\n",
    "tol2 = []\n",
    "with open(directory + hyp +'/recommend' + '.txt','w') as file:\n",
    "    for i in tqdm(range(len(dev_users_list)),mininterval=10):\n",
    "        \n",
    "        recommend_all=[]\n",
    "        uid = dev_users_list[i]\n",
    "        aid = i # author index \n",
    "        \n",
    "        for j in range(5000):\n",
    "            if uid == test_users_list[j]:\n",
    "                i = j\n",
    "                break\n",
    "        \n",
    "        # 현재 유저가 읽은 following list\n",
    "        ufl = users_following_lists[i]\n",
    "        if(len(ufl) > 0):\n",
    "            ufl  = ufl[0]\n",
    "            \n",
    "        # 현재 유저가 읽은 모든 글 , \n",
    "        r = article_seen_by_testuser[str(i)]\n",
    "        # 최신에 읽은 글들이 사라지지 않게 뒤집고 중복 제거하기\n",
    "        r = list(reversed(r))\n",
    "        s = []\n",
    "        \n",
    "        for a in range(len(r)):\n",
    "            if r[a] not in s:\n",
    "                s.append(r[a])\n",
    "        r = list(reversed(s))\n",
    "\n",
    "        # 최신 읽은 작가 정보를 업데이트\n",
    "        # type(author_and_cnt) = dict 임\n",
    "        author_and_cnt = author_lists[aid]\n",
    "        if hyp_author > 0:\n",
    "            \n",
    "            # 일단 recent 2주 top 58647 에서\n",
    "            recommend_author = []\n",
    "            cnt_author = 0            \n",
    "            author_consider_set = set()\n",
    "            \n",
    "            for key, value in author_and_cnt.items(): #이거를 3개 만들어서 하는 게 NDCG 높이는데 기여할듯\n",
    "                author = key\n",
    "                cnt = value\n",
    "                author_consider_set.add(key)\n",
    "                # 2월 14일 ~ 3월 1일간 인기글 30419개 중에 있으면 뽑기\n",
    "                author_all_article_1 = FEB_top_58647[FEB_top_58647['author_id'] == author].sort_values(by='reg_dt',ascending=False) # 최신에 작성한 글들의 인기순이겠지 # 더 줄여봐도 될 듯\n",
    "                cnt_1 = 0\n",
    "                for j in range(len(author_all_article_1)):\n",
    "                    if(cnt_1 >= cnt): break\n",
    "                    artic = list(author_all_article_1[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_author:\n",
    "                            recommend_author.append(artic)\n",
    "                            cnt_1 +=1\n",
    "                \n",
    "                #  3월 1일 ~ 3월 7일에 쓰여진 글 있으면 append\n",
    "                author_all_article_2 = MAR_article_1[MAR_article_1['author_id'] == author]\n",
    "                cnt_2 = 0\n",
    "                for j in range(len(author_all_article_2)):\n",
    "                    if(cnt_2 >= cnt): break\n",
    "                    artic = list(author_all_article_2[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_author:\n",
    "                            recommend_author.append(artic)\n",
    "                            cnt_2 +=1\n",
    "                            \n",
    "                #  3월 7일 ~ 3월 14일에 쓰여진 글 있으면 append\n",
    "                author_all_article_3 = MAR_article_2[MAR_article_2['author_id'] == author]\n",
    "                cnt_3 = 0\n",
    "                for j in range(len(author_all_article_3)):\n",
    "                    if(cnt_3 >= cnt): break\n",
    "                    artic = list(author_all_article_3[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_author:\n",
    "                            recommend_author.append(artic)\n",
    "                            cnt_3 +=1\n",
    "                \n",
    "            \n",
    "            # 100 개 이상 추천될 수 있으니 자르기 | hyper parameter 만큼 자르기\n",
    "            recommend_author = recommend_author[:hyp_author] # 체크\n",
    "            ral.append(len(recommend_author))\n",
    "            for artic in recommend_author:\n",
    "                if artic not in recommend_all:\n",
    "                    recommend_all.append(artic)\n",
    "            \n",
    "        # 구독자를 먼저 넣어보자\n",
    "        # recent때 활용하지 않은 구독자 정보를 이용한다\n",
    "        ufl_not_yet = []\n",
    "        for t in range(len(ufl)):\n",
    "            if ufl[t] not in author_consider_set:\n",
    "                ufl_not_yet.append(ufl[t])\n",
    "\n",
    "        ufls_i = 0\n",
    "        if len(ufl_not_yet) > 0:\n",
    "\n",
    "            for author in ufl_not_yet: # 여기도 제일 많이 읽은 작가 순으로 넣어주는게 바람직하겠지?\n",
    "                if(len(recommend_all) >= 100): break\n",
    "                author_all_article_1 = FEB_top_58647[FEB_top_58647['author_id'] == author].sort_values(by='reg_dt',ascending=False) # top 50000 or to 10000 으로 바꿔서 비\n",
    "\n",
    "                cnt_1 = 0\n",
    "                for j in range(len(author_all_article_1)):\n",
    "                    if(len(recommend_all) >= 80): break #이것도 조정 필요\n",
    "\n",
    "                    artic = list(author_all_article_1[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_all:\n",
    "                            recommend_all.append(artic)\n",
    "                            cnt_1 +=1\n",
    "                            ufls_i+=1\n",
    "\n",
    "\n",
    "                #  3월 1일 ~ 3월 7일에 쓰여진 글 있으면 append\n",
    "\n",
    "                author_all_article_2 = MAR_article_1[MAR_article_1['author_id'] == author]\n",
    "                cnt_2 = 0\n",
    "                for j in range(len(author_all_article_2)):\n",
    "                    if(len(recommend_all) >= 90): break #얘도 조정 필요하고\n",
    "                    artic = list(author_all_article_2[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_all:\n",
    "                            recommend_all.append(artic)\n",
    "                            cnt_2 +=1\n",
    "                            ufls_i+=1\n",
    "\n",
    "                #  3월 7일 ~ 3월 14일에 쓰여진 글 있으면 append\n",
    "                author_all_article_3 = MAR_article_2[MAR_article_2['author_id'] == author]\n",
    "                cnt_3 = 0\n",
    "                for j in range(len(author_all_article_3)):\n",
    "                    if(len(recommend_all) >= 100): break #얘는 그대로 뭐 둬도 (entropy가 높지 않으면 바로 아래 걸로)\n",
    "                    artic = list(author_all_article_3[j:j+1]['article_id'])[0]\n",
    "                    if artic not in r:\n",
    "                        if artic not in recommend_all:\n",
    "                            recommend_all.append(artic)\n",
    "                            cnt_3 +=1\n",
    "                            ufls_i+=1\n",
    "        tol.append(len(recommend_all))\n",
    "        \n",
    "        # 최신에 본 글 위주로 similarity 조사\n",
    "        if(len(r) >= hyp_read_cnt):\n",
    "            wtil = list(word_to_id.keys())\n",
    "            countt +=1\n",
    "            if(hyp_recent_article_len > len(r)):\n",
    "                hyp_recent_article_len = len(r)\n",
    "            r = r[-hyp_recent_article_len:]\n",
    "            r = list(reversed(r))\n",
    "            siml_cnt = 0\n",
    "            for j in range(len(r)):\n",
    "                if(siml_cnt>= hyp_sim): break\n",
    "                if(r[j] not in wtil):\n",
    "                    r[j] = 'UNK'\n",
    "                s = article_similarity[word_to_id[r[j]]]\n",
    "                sim_list = s[:hyp_top_k]\n",
    "                for k in range(len(sim_list)):\n",
    "                    if sim_list[k] not in recommend_all:\n",
    "                        recommend_all.append(sim_list[k])\n",
    "                        siml_cnt+=1\n",
    "                        if(siml_cnt>= hyp_sim): break\n",
    "            siml.append(siml_cnt)\n",
    "            if len(recommend_all)>=100:\n",
    "                recommend_all = recommend_all[:100]\n",
    "        \n",
    "        \n",
    "        tol2.append(len(recommend_all))\n",
    "        \n",
    "        if(len(recommend_all) >= 100):\n",
    "            recommend_all = recommend_all[:100]\n",
    "        else:\n",
    "            # 남으면 FEB_top 중 아무거나 뽑아서 주고\n",
    "            # following list 있으면 여기에 활용해도 좋을듯\n",
    "            cntttt+=1\n",
    "            \n",
    "                    \n",
    "            for x in FEB_top_58647_list:\n",
    "                if x not in recommend_all:\n",
    "                    recommend_all.append(x)\n",
    "                    if(len(recommend_all) == 100): break\n",
    "                        \n",
    "        # 다시 한 번 더 점검\n",
    "        if(len(recommend_all) > 100):\n",
    "            recommend_all = recommend_all[:100]\n",
    "        \n",
    "\n",
    "        recommend_normal = ''\n",
    "        for x in recommend_all:\n",
    "            recommend_normal += ' '+ x\n",
    "\n",
    "        file.write(uid + recommend_normal)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
