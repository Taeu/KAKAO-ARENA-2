{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta, datetime\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "directory = 'D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/'\n",
    "font_path = directory + 'NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path, size=10).get_name()\n",
    "plt.rc('font', family=font_name, size=12)\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['#d6866a498157771069fdf15361cb012b', '#f963fb8c5d9d14d503fc4e80bd8617b4', '#87a6479c91e4276374378f1d28eb307c', '#677e984e245b344f61dc5d3cc1f352c8', '#519f45eb14e4807e8714fb7e835463eb']\n",
      "5000\n",
      "['#7ee14df8642a7925b1465ff5c89efe5b', '#8420b9385b282028eebf1ad6b4a221c0', '#c9b31d8b64357f5854b1ba55b32eb6d3', '#9bb1e13b5481fa3737af20870b25c723', '#37d5f99a7f12c9ba90c4e2ac92e54ab6']\n"
     ]
    }
   ],
   "source": [
    "dev_users_path ='D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/predict/predict/dev.users'\n",
    "dev_users_list = []\n",
    "with open(dev_users_path, 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "    dev_users_list = lines\n",
    "    del lines\n",
    "for i in range(len(dev_users_list)):\n",
    "    dev_users_list[i] = dev_users_list[i].replace('\\n','')\n",
    "    \n",
    "test_users_path ='D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/predict/predict/test.users'\n",
    "test_users_list = []\n",
    "with open(test_users_path, 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "    test_users_list = lines\n",
    "    del lines\n",
    "for i in range(len(test_users_list)):\n",
    "    test_users_list[i] = test_users_list[i].replace('\\n','')\n",
    "\n",
    "print(len(dev_users_list))\n",
    "print(dev_users_list[:5])\n",
    "print(len(test_users_list))\n",
    "print(test_users_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_new = []\n",
    "with open(directory + 'recommend.txt') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        recommend_new.append(line)\n",
    "recommend_new_top_100 = recommend_new[0][33:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @brunch_151 @sweetannie_145 @chofang1_15 @seochogirl_1 @seochogirl_16 @seochogirl_18 @seochogirl_17 @conbus_43 @tenbody_1305 @brunch_152 @seochogirl_11 @hjl0520_26 @seochogirl_12 @intlovesong_28 @seochogirl_13 @seochogirl_14 @dailylife_207 @seochogirl_15 @wootaiyoung_85 @seochogirl_10 @steven_179 @seochogirl_28 @seochogirl_20 @seochogirl_29 @noey_130 @shindong_38 @seochogirl_8 @shanghaiesther_46 @tenbody_1164 @seochogirl_7 @seochogirl_6 @mothertive_66 @seochogirl_2 @seochogirl_9 @seochogirl_3 @deckey1985_51 @kotatsudiary_66 @bzup_281 @seochogirl_4 @roysday_314 @hongmilmil_33 @seochogirl_5 @ohmygod_42 @boot0715_115 @hyehyodam_19 @hjl0520_28 @wikitree_54 @fuggyee_108 @brunch_149 @syshine7_57 @mightysense_9 @roysday_313 @sweetannie_146 @onyouhe_98 @roysday_307 @ladybob_30 @13july_92 @dryjshin_255 @aemae-human_15 @dailylife_219 @tamarorim_133 @sunnysohn_60 @keeuyo_57 @anetmom_52 @ladybob_29 @moment-yet_155 @yoriyuri_12 @dong02_1372 @kidjaydiary_6 @curahee_7 @thinkaboutlove_234 @thebluenile86_4 @scienceoflove_5 @hjl0520_27 @jijuyeo_9 @anti-essay_150 @13july_94 @seochogirl_41 @dryjshin_256 @aemae-human_9 @mentorgrace_8 @anetmom_47 @psychiatricnews_18 @namgizaa_46 @dailylife_178 @boot0715_111 @moment-yet_157 @keeuyo_56 @kam_65 @honeytip_945 @choyoungduke_157 @jinbread_111 @kam_60 @dreamwork9_25 @dancingsnail_65 @kyungajgba_60 @syshine7_56 @dancingsnail_64 @anti-essay_153 @mariandbook_413'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_new_top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory + 'article_by_testuser.json') as f:\n",
    "    article_seen_by_testuser = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "대회 참가자에게 제공하는 데이터에는 브런치 사용자가 2019년 3월 1일까지 소비한 글에 대한 정보가 포함되어 있습니다. 제공 데이터와 평가 데이터의 일부 기간, 2019년 2월 22일부터 2019년 3월 1일까지 겹치는 점에 유념하세요. 그러나 2019년 2월 22일부터 2019년 3월 1일까지 제공된 데이터와 평가 데이터에 중복된 소비 이력은 없습니다. 즉, 어떤 사용자가 해당 기간에 5개의 글을 소비했는데, 그중 3개는 참가자에게 제공될 수 있고, 2개는 평가 데이터로 활용될 수 있습니다. 이 중첩된 기간에는 어떤 사용자든 제공된 데이터와 평가 데이터에 동일하게 소비한 글은 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_similarity = np.load(directory+'article_similarity_t.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_similarity = article_similarity.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory + 'word_to_id.json') as f:\n",
    "    word_to_id  = json.load(f)\n",
    "\n",
    "with open(directory + 'id_to_word.json') as f:\n",
    "    id_to_word = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134994\n",
      "505842\n",
      "134994\n"
     ]
    }
   ],
   "source": [
    "print(len(article_similarity))\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rntl = recommend_new_top_100.split(' ')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @brunch_151 @sweetannie_145 @chofang1_15 @seochogirl_1 @seochogirl_16 @seochogirl_18 @seochogirl_17 @conbus_43 @tenbody_1305 @brunch_152 @seochogirl_11 @hjl0520_26 @seochogirl_12 @intlovesong_28 @seochogirl_13 @seochogirl_14 @dailylife_207 @seochogirl_15 @wootaiyoung_85 @seochogirl_10 @steven_179 @seochogirl_28 @seochogirl_20 @seochogirl_29 @noey_130 @shindong_38 @seochogirl_8 @shanghaiesther_46 @tenbody_1164 @seochogirl_7 @seochogirl_6 @mothertive_66 @seochogirl_2 @seochogirl_9 @seochogirl_3 @deckey1985_51 @kotatsudiary_66 @bzup_281 @seochogirl_4 @roysday_314 @hongmilmil_33 @seochogirl_5 @ohmygod_42 @boot0715_115 @hyehyodam_19 @hjl0520_28 @wikitree_54 @fuggyee_108 @brunch_149 @syshine7_57 @mightysense_9 @roysday_313 @sweetannie_146 @onyouhe_98 @roysday_307 @ladybob_30 @13july_92 @dryjshin_255 @aemae-human_15 @dailylife_219 @tamarorim_133 @sunnysohn_60 @keeuyo_57 @anetmom_52 @ladybob_29 @moment-yet_155 @yoriyuri_12 @dong02_1372 @kidjaydiary_6 @curahee_7 @thinkaboutlove_234 @thebluenile86_4 @scienceoflove_5 @hjl0520_27 @jijuyeo_9 @anti-essay_150 @13july_94 @seochogirl_41 @dryjshin_256 @aemae-human_9 @mentorgrace_8 @anetmom_47 @psychiatricnews_18 @namgizaa_46 @dailylife_178 @boot0715_111 @moment-yet_157 @keeuyo_56 @kam_65 @honeytip_945 @choyoungduke_157 @jinbread_111 @kam_60 @dreamwork9_25 @dancingsnail_65 @kyungajgba_60 @syshine7_56 @dancingsnail_64 @anti-essay_153 @mariandbook_413'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_new_top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rntl = recommend_new_top_100.split(' ')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:01<00:00, 1791.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter\n",
    "hyp_recent_article_len = 20\n",
    "hyp_top_k = 3\n",
    "hyp_read_cnt = 10\n",
    "isdev = 1\n",
    "\n",
    "hyp = str(hyp_read_cnt)+'_'+str(hyp_recent_article_len)+'_'+str(hyp_top_k) + '_'+'dev'\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(directory + hyp )):\n",
    "        os.makedirs(os.path.join(directory + hyp))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise\n",
    "            \n",
    "countt = 0\n",
    "cntttt = 0\n",
    "\n",
    "with open(directory + hyp +'/recommend' + '.txt','w') as file:\n",
    "    for i in tqdm(range(len(dev_users_list)),mininterval=10):\n",
    "        recommend_all=[]\n",
    "        recommend_all += rntl[:10]\n",
    "        uid = dev_users_list[i]\n",
    "        for j in range(5000):\n",
    "            if uid == test_users_list[j]:\n",
    "                i = j\n",
    "                break\n",
    "        \n",
    "        r = article_seen_by_testuser[str(i)]\n",
    "\n",
    "        if(len(r) >= hyp_read_cnt):\n",
    "            countt +=1\n",
    "            if(hyp_recent_article_len > len(r)):\n",
    "                hyp_recent_article_len = len(r)\n",
    "            r = r[-hyp_recent_article_len:]\n",
    "            r = list(reversed(r))\n",
    "\n",
    "            for j in range(len(r)):\n",
    "                s = article_similarity[word_to_id[r[j]]]\n",
    "                sim_list = s[:hyp_top_k]\n",
    "                for k in range(len(sim_list)):\n",
    "                    if sim_list[k] not in recommend_all:\n",
    "                        recommend_all.append(sim_list[k])\n",
    "\n",
    "            if len(recommend_all)>=100:\n",
    "                recommend_all = recommend_all[:100]\n",
    "            else:\n",
    "                \n",
    "                idx = 0 \n",
    "                while(len(recommend_all) < 100):\n",
    "                    if(idx >= len(recommend_all)): break\n",
    "                    \n",
    "                    s = article_similarity[word_to_id[recommend_all[idx]]]\n",
    "                    sim_list = s[:hyp_top_k]\n",
    "                    for j in range(len(sim_list)):\n",
    "                        if sim_list[j] not in recommend_all:\n",
    "                            recommend_all.append(sim_list[j])\n",
    "                    idx += 1\n",
    "                \n",
    "                \n",
    "                if(len(recommend_all)>=100):\n",
    "                    recommend_all = recommend_all[:100]\n",
    "                else:\n",
    "                    for x in rntl:\n",
    "                        if x not in recommend_all:\n",
    "                            recommend_all.append(x)\n",
    "                            if(len(recommend_all) == 100): break\n",
    "\n",
    "            recommend_normal = ''\n",
    "            for x in recommend_all:\n",
    "                recommend_normal += ' '+ x\n",
    "\n",
    "            file.write(uid + recommend_normal)\n",
    "            file.write('\\n')\n",
    "\n",
    "        else :\n",
    "            recommend_normal = recommend_new_top_100\n",
    "            file.write(uid + recommend_normal)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
