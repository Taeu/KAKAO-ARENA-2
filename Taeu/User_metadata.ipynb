{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta, datetime\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/'\n",
    "font_path = directory + 'NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path, size=10).get_name()\n",
    "plt.rc('font', family=font_name, size=12)\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MetaData preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>display_url</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>782</td>\n",
       "      <td>https://brunch.co.kr/@bookdb/782</td>\n",
       "      <td>@bookdb_782</td>\n",
       "      <td>[여행, 호주, 국립공원]</td>\n",
       "      <td>8982</td>\n",
       "      <td>1474944427000</td>\n",
       "      <td>세상 어디에도 없는 호주 Top 10</td>\n",
       "      <td>사진으로 옮기기에도 아까운, 리치필드 국립공원</td>\n",
       "      <td>@bookdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>https://brunch.co.kr/@kohwang56/81</td>\n",
       "      <td>@kohwang56_81</td>\n",
       "      <td>[목련꽃, 아지랑이, 동행]</td>\n",
       "      <td>12081</td>\n",
       "      <td>1463092749000</td>\n",
       "      <td></td>\n",
       "      <td>[시] 서러운 봄</td>\n",
       "      <td>@kohwang56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://brunch.co.kr/@hannahajink/4</td>\n",
       "      <td>@hannahajink_4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1447997287000</td>\n",
       "      <td>무엇 때문에</td>\n",
       "      <td>무엇을 위해</td>\n",
       "      <td>@hannahajink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>https://brunch.co.kr/@bryceandjuli/88</td>\n",
       "      <td>@bryceandjuli_88</td>\n",
       "      <td>[감정, 마음, 위로]</td>\n",
       "      <td>16315</td>\n",
       "      <td>1491055161000</td>\n",
       "      <td></td>\n",
       "      <td>싫다</td>\n",
       "      <td>@bryceandjuli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>https://brunch.co.kr/@mijeongpark/34</td>\n",
       "      <td>@mijeongpark_34</td>\n",
       "      <td>[유럽여행, 더블린, 아일랜드]</td>\n",
       "      <td>29363</td>\n",
       "      <td>1523292942000</td>\n",
       "      <td>#7. 내 친구의 집은 어디인가</td>\n",
       "      <td>Dubliner#7</td>\n",
       "      <td>@mijeongpark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                            display_url                id  \\\n",
       "0         782       https://brunch.co.kr/@bookdb/782       @bookdb_782   \n",
       "1          81     https://brunch.co.kr/@kohwang56/81     @kohwang56_81   \n",
       "2           4    https://brunch.co.kr/@hannahajink/4    @hannahajink_4   \n",
       "3          88  https://brunch.co.kr/@bryceandjuli/88  @bryceandjuli_88   \n",
       "4          34   https://brunch.co.kr/@mijeongpark/34   @mijeongpark_34   \n",
       "\n",
       "        keyword_list  magazine_id         reg_ts             sub_title  \\\n",
       "0     [여행, 호주, 국립공원]         8982  1474944427000  세상 어디에도 없는 호주 Top 10   \n",
       "1    [목련꽃, 아지랑이, 동행]        12081  1463092749000                         \n",
       "2                 []            0  1447997287000                무엇 때문에   \n",
       "3       [감정, 마음, 위로]        16315  1491055161000                         \n",
       "4  [유럽여행, 더블린, 아일랜드]        29363  1523292942000     #7. 내 친구의 집은 어디인가   \n",
       "\n",
       "                       title        user_id  \n",
       "0  사진으로 옮기기에도 아까운, 리치필드 국립공원        @bookdb  \n",
       "1                  [시] 서러운 봄     @kohwang56  \n",
       "2                     무엇을 위해   @hannahajink  \n",
       "3                         싫다  @bryceandjuli  \n",
       "4                 Dubliner#7   @mijeongpark  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_json(directory + 'metadata.json', lines=True)\n",
    "metadata.shape # (643104, 9)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "magazine = pd.read_json(directory + 'magazine.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>magazine_tag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38842</td>\n",
       "      <td>[브런치북, 육아일기, 대화법, 들려주고픈이야기]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11540</td>\n",
       "      <td>[tea, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11541</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            magazine_tag_list\n",
       "0  38842  [브런치북, 육아일기, 대화법, 들려주고픈이야기]\n",
       "1  11540                  [tea, food]\n",
       "2  11541                       [food]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magazine[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "magazine_keyword = []\n",
    "for x in metadata['magazine_id']:\n",
    "    if(x != 0 ):\n",
    "        if(list(magazine[magazine['id']==x]['magazine_tag_list']) != []):\n",
    "            magazine_keyword.append(list(magazine[magazine['id']==x]['magazine_tag_list'])[0])\n",
    "        else:\n",
    "            magazine_keyword.append([])\n",
    "    else:\n",
    "        magazine_keyword.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(magazine_keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword_list Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_keyword :  3077864\n"
     ]
    }
   ],
   "source": [
    "keywordlist = metadata['keyword_list'].copy()\n",
    "text_keyword = []\n",
    "# metadata keyword\n",
    "for x_list in keywordlist:\n",
    "    if len(x_list) != 0:\n",
    "        for x in x_list:\n",
    "            text_keyword.append(x)\n",
    "# magazine_keyword\n",
    "for x_list in magazine_keyword:\n",
    "    if len(x_list) != 0 :\n",
    "        for x in x_list:\n",
    "            text_keyword.append(x)\n",
    "            \n",
    "print('text_keyword : ',len(text_keyword))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary\n",
    "# generate dataset, dictionary for word\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in text_keyword:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "# 공백 표시할 어휘 : eos\n",
    "word_to_id['eos'] = len(word_to_id)\n",
    "id_to_word[len(word_to_id)-1] = 'eos'\n",
    "# vocab에 없는 단어는 UNK로 표시\n",
    "word_to_id['UNK'] = len(word_to_id)\n",
    "id_to_word[len(word_to_id)-1] = 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11725560"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_kr = []\n",
    "for i in range(len(keywordlist)):\n",
    "    if len(keywordlist[i]) != 0:\n",
    "        for x in keywordlist[i]:\n",
    "            corpus_kr.append(x)\n",
    "    if len(magazine_keyword[i]) != 0 :\n",
    "        for x in magazine_keyword[i]:\n",
    "            corpus_kr.append(x)\n",
    "    if len(keywordlist[i]) != 0:\n",
    "        for x in keywordlist[i]:\n",
    "            corpus_kr.append(x)\n",
    "    if len(magazine_keyword[i]) != 0 :\n",
    "        for x in magazine_keyword[i]:\n",
    "            corpus_kr.append(x)\n",
    "    if len(keywordlist[i]) != 0:\n",
    "        for x in keywordlist[i]:\n",
    "            corpus_kr.append(x)\n",
    "    if len(magazine_keyword[i]) != 0 :\n",
    "        for x in magazine_keyword[i]:\n",
    "            corpus_kr.append(x)\n",
    "    if len(keywordlist[i])!=0 or len(magazine_keyword[i]) != 0:\n",
    "        for x in range(4):\n",
    "            corpus_kr.append('eos')\n",
    "            \n",
    "len(corpus_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word_to_id[w] for w in corpus_kr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 410, 769, 6627, 0, 1, 2, 410, 769, 6627, 0, 1, 2]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_id, id_to_word, corpus\n",
    "\n",
    "vocabulary_size = len(word_to_id) # ~~= 96864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# title 은 생략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_title :  2490429\n"
     ]
    }
   ],
   "source": [
    "# title \n",
    "josa1 = ['이','가','을','를','에','은','는','께','로','의','과','와','고','아','야','도','다']\n",
    "josa2 = ['께서','에서','한테','더러','으로','보다','처럼','만큼','같이','조차','마저','까지','부터','이다','에도']\n",
    "josa3 = ['으로는','께서는','한테는','처럼은','만큼은','같이는','마저도','조차도','까지도','습니다',]\n",
    "\n",
    "titlelist = metadata['title'].copy()\n",
    "\n",
    "text_title = []\n",
    "for x_title in titlelist:\n",
    "    if len(x_title) != 0:\n",
    "        for space in list(['.',',','/','@','-','·','?','...','\\xa0']):\n",
    "            x_title = x_title.replace(space,' ')\n",
    "        for remov in ['#','^','*','[',']','(',')',\"'\",'\"']:\n",
    "            x_title = x_title.replace(remov,'')\n",
    "        x_title.lower()\n",
    "        words = x_title.split(' ')\n",
    "        for word in words:\n",
    "            if len(word) != 0:\n",
    "                if word[-3:] in josa3:\n",
    "                    word = word[:-3]\n",
    "                if len(word) != 0 :\n",
    "                    if word[-2:] in josa2:\n",
    "                        word = word[:-2]\n",
    "                    if len(word) != 0:\n",
    "                        if word[-1] in josa1:\n",
    "                            word = word[:-1]\n",
    "                text_title.append(word)\n",
    "print('text_title : ',len(text_title))\n",
    "word_to_id_title = word_to_id.copy()\n",
    "id_to_word_title = id_to_word.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow skip, word2vec 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import collections\n",
    "def generate_batch(data, batch_size, num_skips, skip_window, data_index):\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "\n",
    "    span = 2 * skip_window + 1                      # context = skip_window + target + skip_window\n",
    "    assert span > num_skips\n",
    "\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)   # 다음 단어 인덱스로 이동. len(data) = 17005207\n",
    "\n",
    "    for i in range(batch_size // num_skips):\n",
    "\n",
    "        targets = list(range(span))     # 1. 0부터 span-1까지의 정수로 채운 다음\n",
    "        targets.pop(skip_window)        # 2. skip_window번째 삭제\n",
    "        np.random.shuffle(targets)      # 3. 난수를 사용해서 섞는다.\n",
    "\n",
    "        start = i * num_skips\n",
    "        batch[start:start+num_skips] = buffer[skip_window]\n",
    "\n",
    "        for j in range(num_skips):\n",
    "            labels[start+j, 0] = buffer[targets[j]]\n",
    "\n",
    "        # 새로운 요소가 들어가면서 가장 먼저 들어간 데이터 삭제\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, labels, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 16:03:12.183416 17092 deprecation.py:323] From D:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0717 16:03:12.395745 17092 deprecation.py:506] From <ipython-input-56-be20dda57574>:41: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Step 4: skip-gram 모델 구축\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "batch_size = 128        # 일반적으로 16 <= batch_size <= 512\n",
    "embedding_size = 128    # embedding vector 크기\n",
    "skip_window = 1         # target 양쪽의 단어 갯수\n",
    "num_skips = 2           # 컨텍스트로부터 생성할 레이블 갯수\n",
    "\n",
    "valid_size = 16     # 유사성을 평가할 단어 집합 크기\n",
    "valid_window = 100  # 앞쪽에 있는 분포들만 뽑기 위한 샘플\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # negative 샘플링 갯수\n",
    "\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "truncated = tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                                stddev=1.0 / math.sqrt(embedding_size))\n",
    "nce_weights = tf.Variable(truncated)\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "# embeddings 벡터.\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "# 배치 데이터에 대해 NCE loss 평균 계산\n",
    "nce_loss = tf.nn.nce_loss(weights=nce_weights,\n",
    "                          biases=nce_biases,\n",
    "                          labels=train_labels,\n",
    "                          inputs=embed,\n",
    "                          num_sampled=num_sampled,\n",
    "                          num_classes=vocabulary_size)\n",
    "loss = tf.reduce_mean(nce_loss)\n",
    "\n",
    "# SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "# 유사도를 계산하기 위한 모델. 학습 모델은 optimizer까지 구축한 걸로 종료.\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(96864), Dimension(128)])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(16), Dimension(96864)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 0 : 324.4151611328125\n",
      "Nearest to 출판: 아빠육아, 청소년노동, 인간관계도, 전략실행력, 이호연, 옥잠화, 제품디자이너, 산수유축제\n",
      "Nearest to 아이돌: 오늘질문, 가든, 파라과이, 전몽각, 터키리라, 미네랄온천, 만족하는연습, 야행축제\n",
      "Nearest to 생각: 방해금지모드, 감정다툼, 텃새, 원칙에의한경영, 바이오연료, 교육프로그램, 제주도출판사, 친노\n",
      "Nearest to 사회복지사: 정치도서, 제니퍼, 교육강좌, 서예대전, 이지훈기자, 하도급계약, 무크지, 오사카여행\n",
      "Nearest to 방송연예: 비폭력운동, 숫돌, 인간로봇, 퇴장, 첩보, 수사관, 롯데하이마트, 국력\n",
      "Nearest to 부동산경매변호사: 브라질치안, 에바항공, 녹차콜라, 제중원, 투스카니의태양, 원어민교사, 항일, 코르크마개\n",
      "Nearest to 단상: 법정통역, 책마을, 부자운세, 중국중국, 노동착취, 디센던트, 다코타패닝, 감상\n",
      "Nearest to 교육: 내맘대로영화읽기, 딸기바구니, 매화축제, 국민드론, 우리동네, 라면국물티백, 바보상자, 기온\n",
      "Nearest to 취업: 아메리카여행, 로잔선언, 최소한, 스포티지r, 오염, 충동인류, 싱글오일, 사천시\n",
      "Nearest to 마케팅: 윙크, 인생정리, 돈나무, 세운상가, 철학서적, 주사바늘, 앰네스티, 실사출력물\n",
      "Nearest to 방송: 한민족, 복합체, 명란계란말이, 운동모임, 아이나비, 딱정벌레, 마음으로소통하다, 문무대왕릉\n",
      "Nearest to 감성에세이: 신재생에너지, 협상바이블, 지산락페, 정기과정, 철원기행, 상상력가동, 놀이법, 엄마감정\n",
      "Nearest to 하이에나: 힌트, 설매재, 전쟁기자, 언차티드, 도시서점, 미크로네시아, 지방소멸, 엔드\n",
      "Nearest to 버스: 나고야메시, 인권조례, 정월대보름행사, 전두환, 마을공동체미디어, 스키장오픈, 제주스노쿨링명소, 뎅기열\n",
      "Nearest to 행복: 운두령, 관계부사, 고당봉, 스티브, 화물연대, 모아이석상, 신체보험, 완독\n",
      "Nearest to 빵가게: SK와이번스, 데모데이, 간장감자조림, 공유경제활성화, 윤리철학, 한국신문방송협회, 퇴사기념, 연금수령\n",
      "Average loss at step 10000 : 76.30717409405709\n",
      "Average loss at step 20000 : 23.532313819646834\n",
      "Average loss at step 30000 : 12.997146683371067\n",
      "Average loss at step 40000 : 8.915860731518269\n",
      "Average loss at step 50000 : 7.350286977863312\n",
      "Average loss at step 60000 : 6.336316628003121\n",
      "Average loss at step 70000 : 5.710062470841407\n",
      "Average loss at step 80000 : 5.416731224888563\n",
      "Average loss at step 90000 : 5.125524108052254\n",
      "Average loss at step 100000 : 4.871042395621538\n",
      "Nearest to 출판: 독서, 독후감, 창조루틴, 출판사, 작가, 카메라렌즈로, 사슴남매, 독립출판\n",
      "Nearest to 아이돌: 리뷰, 영화감상, 야행축제, 예산반영, 비평, 음악, 소셜벤쳐, 영일고등학교\n",
      "Nearest to 생각: 삶, 사람, 행복, 인간관계, 자신, 시선, 시간, 일상\n",
      "Nearest to 사회복지사: 이지훈기자, 교육강좌, 레인보우, 하리하리, crowdy, 실버생활, 선거연령, 영업신고\n",
      "Nearest to 방송연예: 숫돌, 비폭력운동, 인간로봇, 첩보, 카펠교, 퇴장, 운석, 제주한달살이\n",
      "Nearest to 부동산경매변호사: 브라질치안, 투스카니의태양, 항일, 코르크마개, 위드이노베이션, 좀비소년, 경쟁법, 동부금융\n",
      "Nearest to 단상: 급여명세서, 북경여행, 인사이드, 영화소식, 공감, 자살유가족, 새벽명상, 인물사전\n",
      "Nearest to 교육: 공부, 수업, 아이, 학교, 촛불아이, 영어캠프, 부모, 윤리교사\n",
      "Nearest to 취업: 면접, 이직, 회사, 진로, 채용, 개발자, 자소서, 직장인\n",
      "Nearest to 마케팅: 브랜드, 경영, 스타트업, 비즈니스, IT, 광고, Drawing, 우주만화\n",
      "Nearest to 방송: 콘텐츠, 넷플릭스, 김태근, 강남대로, 영일고등학교, 복합체, 오토리스, 호스피스상담\n",
      "Nearest to 감성에세이: 감성, 황태영, doctor, 사랑, 그리움, 그림에세이, 새벽명상, 이별\n",
      "Nearest to 하이에나: 블루멤버스, 기온거리, 지방소멸, 여행만화, 패트리어트, 비상연락처, 언저리, 스카프\n",
      "Nearest to 버스: 뎅기열, 한강시민공원, 우체국택배, 친구, 전시감상, 창조루틴, 겔러리, 여러가지이야기\n",
      "Nearest to 행복: 인생, 시간, 사람, 생각, 삶, 세상, 친구, 사랑\n",
      "Nearest to 빵가게: SK와이번스, 수면교육, 녹두서평, 아이, 축제기간, 회계보고, 간장감자조림, 생명창조\n",
      "Average loss at step 110000 : 4.725965457701683\n",
      "Average loss at step 120000 : 4.581595895946026\n",
      "Average loss at step 130000 : 4.40174430077672\n",
      "Average loss at step 140000 : 4.280498739641905\n",
      "Average loss at step 150000 : 4.236943233525753\n",
      "Average loss at step 160000 : 4.140908833670617\n",
      "Average loss at step 170000 : 3.9570163758158685\n",
      "Average loss at step 180000 : 3.9472167950749397\n",
      "Average loss at step 190000 : 3.1790130387425424\n",
      "Average loss at step 200000 : 2.664325197213888\n",
      "Nearest to 출판: 독립출판, 출간, 출판사, 작가, 편집자, 서점, 문학, 사슴남매\n",
      "Nearest to 아이돌: 음악리뷰, 음악, 콘서트, 음반, 예산반영, 대중음악, 국립해양생물박물관, 음악추천\n",
      "Nearest to 생각: 일상, 마음, 사람, 자신, 사랑, 경험, 시작, 관계\n",
      "Nearest to 사회복지사: 하리하리, 교육강좌, 이지훈기자, 레인보우, 송정, 해당화, 이미지세상, 으아리\n",
      "Nearest to 방송연예: 숫돌, 비폭력운동, 음악사, 인간로봇, 첩보, 퇴장, 카펠교, 제주한달살이\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 물총새, 원어민교사, 여행명언, 이데일리, 꼬리, 박물관\n",
      "Nearest to 단상: 일상, 일기, 에세이, 친구, 급여명세서, 성인취미미술, 대화, 북경여행\n",
      "Nearest to 교육: 수업, 선생님, 공부, 부모, 초등학교, 학원, 학교, 촛불아이\n",
      "Nearest to 취업: 면접, 회사, 취준생, 이직, 채용, 해외취업, 진로, 자소서\n",
      "Nearest to 마케팅: 광고, 전략, 브랜드, 비즈니스, 구글, 브랜딩, 경영, 고객\n",
      "Nearest to 방송: 콘텐츠, 넷플릭스, MBC, 김태근, 노래, 영일고등학교, 자살유가족, 앨범\n",
      "Nearest to 감성에세이: 사진에세이, 사랑, 에세이, 위로, 마음, 시, 눈물, 스트라바\n",
      "Nearest to 하이에나: 힌트, 블루멤버스, 기온거리, 지방소멸, 여행만화, 비상연락처, 패트리어트, 스카프\n",
      "Nearest to 버스: 친구, 부동산서울, 인연, 소주, 우체국택배, 단상, 감기, 풍경\n",
      "Nearest to 행복: 시간, 순간, 마음, 변화, 사람, 삶, 우리, 존재\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 회계보고, 2book1week, 간장감자조림, 수면교육, 축제기간, 생명창조\n",
      "Average loss at step 210000 : 2.6030217619776725\n",
      "Average loss at step 220000 : 2.59343910369277\n",
      "Average loss at step 230000 : 2.5720935687422752\n",
      "Average loss at step 240000 : 2.559473936086893\n",
      "Average loss at step 250000 : 2.5507830488026144\n",
      "Average loss at step 260000 : 2.5413273599982262\n",
      "Average loss at step 270000 : 2.536091088962555\n",
      "Average loss at step 280000 : 2.521485090768337\n",
      "Average loss at step 290000 : 2.5167495354115963\n",
      "Average loss at step 300000 : 2.498852532160282\n",
      "Nearest to 출판: 독립출판, 출판사, 출간, 서점, 작가, 독후감, 도서, 핀란드요리\n",
      "Nearest to 아이돌: 음악리뷰, 음반, 대중음악, 방송, 음악추천, 콘서트, 음악, 블로그페이스북\n",
      "Nearest to 생각: 자신, 우리, 마음, 시간, 사람, 당신, 일상, 황태영\n",
      "Nearest to 사회복지사: 송정, 이지훈기자, 교육강좌, 이미지세상, 하리하리, 레인보우, 제니퍼, 해당화\n",
      "Nearest to 방송연예: 숫돌, 음악사, 비폭력운동, 연극, 인간로봇, 첩보, 퇴장, 제주한달살이\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 물총새, 원어민교사, 제인오스틴, 이데일리, 통영라이더, 꼬리\n",
      "Nearest to 단상: 공감, 일상, 성인취미미술, 창조루틴, 생각, 한전, 소파대신, 급여명세서\n",
      "Nearest to 교육: 수업, 초등학교, 학교, 교사, 디지털노마드생활, 카메라렌즈로, 선생님, 촛불아이\n",
      "Nearest to 취업: 면접, 이직, 취준생, 채용, 자소서, 자기소개서, 취업준비, 직장\n",
      "Nearest to 마케팅: 전략, 고객, 영업, 브랜드, 광고, 마케터, 브랜딩, 경영\n",
      "Nearest to 방송: 콘텐츠, MBC, 넷플릭스, 김태근, 언론, TV, 작동, 노래\n",
      "Nearest to 감성에세이: 감성, 황태영, 창조루틴, 사랑, 그림에세이, 에세이, 어른, 기술개발지원사업\n",
      "Nearest to 하이에나: 힌트, 블루멤버스, 기온거리, 지방소멸, 여행만화, 비상연락처, 패트리어트, 어깨충돌증후군\n",
      "Nearest to 버스: 지하철, 친구, 부동산서울, 우체국택배, 일본공예업계, 강균성, 풍경, 겔러리\n",
      "Nearest to 행복: 시간, 바라본세상, 황태영, 선택, 장애인가족, 시선, 자기계발, 자신\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 회계보고, 간장감자조림, 축제기간, 2book1week, 생명창조, 비치타올\n",
      "Average loss at step 310000 : 2.499994545096159\n",
      "Average loss at step 320000 : 2.491314079910517\n",
      "Average loss at step 330000 : 2.4909582458496096\n",
      "Average loss at step 340000 : 2.4861996953845025\n",
      "Average loss at step 350000 : 2.4895051757514475\n",
      "Average loss at step 360000 : 2.4755602032363413\n",
      "Average loss at step 370000 : 2.515442105597258\n",
      "Average loss at step 380000 : 2.4658394169807436\n",
      "Average loss at step 390000 : 2.4124091206014158\n",
      "Average loss at step 400000 : 2.3999279018461706\n",
      "Nearest to 출판: 출간, 독립출판, 출판사, 서점, 브런치, 원고, 작가, 편집자\n",
      "Nearest to 아이돌: 대중음악, 음악리뷰, 음반, 콘서트, 블로그페이스북, 가사, 방송, 걸그룹\n",
      "Nearest to 생각: 자신, 마음, 일상, 창조루틴, 감정, 친구, 대화, 버스시간\n",
      "Nearest to 사회복지사: 이지훈기자, 송정, 교육강좌, 이미지세상, 제니퍼, 하리하리, 해당화, 정배리\n",
      "Nearest to 방송연예: 음악사, 숫돌, 비폭력운동, 첩보, 인간로봇, 퇴장, 연극, 수사관\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 물총새, 원어민교사, 꼬리, 이데일리, 통영라이더, 제인오스틴\n",
      "Nearest to 단상: 장기연애, 성인취미미술, 잡문, 추억, 급여명세서, 카메라렌즈로, 북경여행, 잡담\n",
      "Nearest to 교육: 수업, 선생님, 초등학교, 윤리교사, 사교육, 카메라렌즈로, 디지털노마드생활, 학교\n",
      "Nearest to 취업: 면접, 취준생, 채용, 취업준비, 진로, 이직, 회사, 자기소개서\n",
      "Nearest to 마케팅: 광고, 브랜드, 전략, 마케터, 고객, 브랜딩, 디지털마케팅, 플랫폼\n",
      "Nearest to 방송: 콘텐츠, MBC, 넷플릭스, 김태근, 머랭, 노래, 작동, 아이돌\n",
      "Nearest to 감성에세이: 공감에세이, 스트라바, 일상에세이, 사랑, 눈물, 신념관리, 그리움, 오지호\n",
      "Nearest to 하이에나: 힌트, 기온거리, 블루멤버스, 여행만화, 지방소멸, 비상연락처, 인생캠프, 어깨충돌증후군\n",
      "Nearest to 버스: 지하철, 친구, 출근, 풍경, 우체국택배, 부동산서울, 일본공예업계, 자리\n",
      "Nearest to 행복: 자신, 당신, 마음, 존재, 지방소모, 황태영, 과정, 시간\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 간장감자조림, 2book1week, 위로, 회계보고, 축제기간, 비치타올\n",
      "Average loss at step 410000 : 2.400671571880579\n",
      "Average loss at step 420000 : 2.3919798160851\n",
      "Average loss at step 430000 : 2.3875432649195196\n",
      "Average loss at step 440000 : 2.363807738447189\n",
      "Average loss at step 450000 : 2.3558697554826735\n",
      "Average loss at step 460000 : 2.3761678666651247\n",
      "Average loss at step 470000 : 2.362508275139332\n",
      "Average loss at step 480000 : 2.349691137140989\n",
      "Average loss at step 490000 : 2.3514485746026037\n",
      "Average loss at step 500000 : 2.338770964753628\n",
      "Nearest to 출판: 출간, 출판사, 작가, 독립출판, 원고, 우지, 편집자, 쿨매트\n",
      "Nearest to 아이돌: 음악리뷰, 대중음악, 음반, 걸그룹, 앨범, 음악추천, 블로그페이스북, 예산반영\n",
      "Nearest to 생각: 자신, 어른, 사람, 마음, 위로, 에세이, 하루, 우리\n",
      "Nearest to 사회복지사: 송정, 이지훈기자, 사회복지, 교육강좌, 이미지세상, 해당화, 정배리, 제니퍼\n",
      "Nearest to 방송연예: 음악사, 숫돌, 비폭력운동, 연극, 첩보, 퇴장, 인간로봇, 수사관\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 진실, 물총새, 원어민교사, 제인오스틴, 통영라이더, 짝사랑\n",
      "Nearest to 단상: 일기, 카메라렌즈로, 일상, 지옥사원, 타나토스, 급여명세서, 새벽, 장기연애\n",
      "Nearest to 교육: 수업, 초등학교, 부모, 선생님, 교사, 학교, 세대론, 카메라렌즈로\n",
      "Nearest to 취업: 면접, 자소서, 취업준비, 취준생, 스펙, 이직, 진로, 자기소개서\n",
      "Nearest to 마케팅: 전략, 광고, 브랜드, 마케터, 디지털마케팅, 경영, 브랜딩, 페이스북\n",
      "Nearest to 방송: 콘텐츠, MBC, TV, 넷플릭스, 드라마, 김태근, 작동, 예능\n",
      "Nearest to 감성에세이: 공감에세이, 에세이, 감성, 상처, 마음, 심리치유, 슬픔, 일상\n",
      "Nearest to 하이에나: 힌트, 기온거리, 블루멤버스, 여행만화, 유럽여행, 지방소멸, 비상연락처, 인생캠프\n",
      "Nearest to 버스: 지하철, 출근, 부동산서울, 출퇴근, 출근길, 운전, 일본공예업계, 자리\n",
      "Nearest to 행복: 자신, 고통, 시작, 고민, 계획, 친구, 장애인가족, 황태영\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 간장감자조림, 회계보고, 2book1week, 아이, 축제기간, 비치타올\n",
      "Average loss at step 510000 : 2.351803903788328\n",
      "Average loss at step 520000 : 2.3373615015625955\n",
      "Average loss at step 530000 : 2.342202883708477\n",
      "Average loss at step 540000 : 2.3514528913080692\n",
      "Average loss at step 550000 : 2.3479113544523718\n",
      "Average loss at step 560000 : 2.378746329629421\n",
      "Average loss at step 570000 : 2.319121305578947\n",
      "Average loss at step 580000 : 2.3085896690189838\n",
      "Average loss at step 590000 : 2.294586422407627\n",
      "Average loss at step 600000 : 2.292508405190706\n",
      "Nearest to 출판: 출간, 출판사, 편집자, 독립출판, 작가, 원고, 서점, 우지\n",
      "Nearest to 아이돌: 대중음악, 음악리뷰, 걸그룹, 케이팝, 음반, 앨범, 아이유, 예산반영\n",
      "Nearest to 생각: 자신, 대화, 기분, 우리, 사람, 과거, 마음, 하루\n",
      "Nearest to 사회복지사: 이지훈기자, 사회복지, 송정, 첫문장과끝문장, 교육강좌, 이미지세상, 과학소통, 해당화\n",
      "Nearest to 방송연예: 음악사, 숫돌, 비폭력운동, 첩보, 연극, 퇴장, 인간로봇, 수사관\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 물총새, 원어민교사, 제인오스틴, 통영라이더, 꼬리, 에바항공\n",
      "Nearest to 단상: 급여명세서, 잡담, 장기연애, 에세이, 일기, 착각, 일상, 카메라렌즈로\n",
      "Nearest to 교육: 수업, 학교, 초등학교, 부모, 선생님, 공부, 자녀교육, 카메라렌즈로\n",
      "Nearest to 취업: 면접, 이직, 자소서, 이력서, 회사, 채용, 스펙, 취업준비\n",
      "Nearest to 마케팅: 광고, 브랜드, 고객, 전략, 마케터, 디지털마케팅, 마케팅전략, 페이스북\n",
      "Nearest to 방송: MBC, 콘텐츠, 드라마, 넷플릭스, 김태근, 작동, 예능, 머랭\n",
      "Nearest to 감성에세이: 사랑, 마음, 상처, 비파, 오일나우, 장폴사르트르, 차박캠핑, 황태영\n",
      "Nearest to 하이에나: 힌트, 여행만화, 기온거리, 사람, 지방소멸, 인생캠프, 어깨충돌증후군, 패트리어트\n",
      "Nearest to 버스: 지하철, 출근, 거리, 출퇴근, 비, 출근길, 일본공예업계, 자리\n",
      "Nearest to 행복: 자신, 시간, 인생, 황태영, 생각, 자유, 순간, 마음\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 조카, 간장감자조림, 축제기간, 회계보고, 2book1week, 메밀\n",
      "Average loss at step 610000 : 2.2859524901151658\n",
      "Average loss at step 620000 : 2.2741607629477976\n",
      "Average loss at step 630000 : 2.262266393864155\n",
      "Average loss at step 640000 : 2.2722621324539185\n",
      "Average loss at step 650000 : 2.261601829499006\n",
      "Average loss at step 660000 : 2.255322346621752\n",
      "Average loss at step 670000 : 2.2692186351716517\n",
      "Average loss at step 680000 : 2.255778421121836\n",
      "Average loss at step 690000 : 2.248324076724052\n",
      "Average loss at step 700000 : 2.2515278066039084\n",
      "Nearest to 출판: 출판사, 출간, 독립출판, 원고, 편집자, 우지, 작가, 서점\n",
      "Nearest to 아이돌: 대중음악, 음악리뷰, 걸그룹, 케이팝, 음반, 앨범, 아이유, 음악\n",
      "Nearest to 생각: 자신, 사람, 의지, 타인, 시, 마음, 시선, 사랑\n",
      "Nearest to 사회복지사: 사회복지, 이지훈기자, 송정, 교육강좌, 진로, 첫문장과끝문장, 이미지세상, 해당화\n",
      "Nearest to 방송연예: 음악사, 비폭력운동, 숫돌, 첩보, 연극, 퇴장, 인간로봇, 수사관\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 물총새, 원어민교사, 통영라이더, 에바항공, 제인오스틴, 문학\n",
      "Nearest to 단상: 비, 급여명세서, 일상, 착각, 잡담, 혁명예술, 장기연애, 일기\n",
      "Nearest to 교육: 수업, 교사, 초등학교, 학교, 부모, 철판볶음, 윤리교사, 학원\n",
      "Nearest to 취업: 면접, 이직, 채용, 이력서, 스펙, 자소서, 취업준비, 취준생\n",
      "Nearest to 마케팅: 브랜드, 전략, 광고, 비즈니스, 경영, 고객, 디지털마케팅, 영업\n",
      "Nearest to 방송: MBC, 콘텐츠, 작동, 김태근, 넷플릭스, 진성리더십, 예능, TV\n",
      "Nearest to 감성에세이: 에세이, 사랑, 삶, 감성, 황태영, 신념관리, 시, 스트라바\n",
      "Nearest to 하이에나: 힌트, 여행만화, 기온거리, 인생캠프, 어깨충돌증후군, 지방소멸, 비상연락처, 패트리어트\n",
      "Nearest to 버스: 지하철, 대중교통, 출퇴근, 출근, 거리, 출근길, 택시, 일본공예업계\n",
      "Nearest to 행복: 친구, 슬픔, 그대, 생일, 장애인가족, 황태영, 눈물, 마음\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 간장감자조림, 조카, 축제기간, 회계보고, 비치타올, 메밀\n",
      "Average loss at step 710000 : 2.2503988994598387\n",
      "Average loss at step 720000 : 2.2661761098504067\n",
      "Average loss at step 730000 : 2.2425131282389166\n",
      "Average loss at step 740000 : 2.3178269807577134\n",
      "Average loss at step 750000 : 2.2574225931048395\n",
      "Average loss at step 760000 : 2.2228523524403574\n",
      "Average loss at step 770000 : 2.229293462711573\n",
      "Average loss at step 780000 : 2.2191437887728216\n",
      "Average loss at step 790000 : 2.212662381452322\n",
      "Average loss at step 800000 : 2.205891172069311\n",
      "Nearest to 출판: 출판사, 출간, 독립출판, 원고, 편집자, 작가, 서점, 우지\n",
      "Nearest to 아이돌: 대중음악, 음악리뷰, 케이팝, 걸그룹, 앨범, 아이유, 방탄소년단, 음반\n",
      "Nearest to 생각: 황태영, 사랑, 어른, 진심, 오늘, 의지, 일상, 창조루틴\n",
      "Nearest to 사회복지사: 사회복지, 이지훈기자, 송정, 교육강좌, 과학소통, 첫문장과끝문장, 이미지세상, 정배리\n",
      "Nearest to 방송연예: 음악사, 비폭력운동, 첩보, 숫돌, 퇴장, 수사관, 에밀졸라, 연극\n",
      "Nearest to 부동산경매변호사: 공연예술, 녹차콜라, 꼬리, 제인오스틴, 물총새, 에바항공, 통영라이더, 원어민교사\n",
      "Nearest to 단상: 착각, 생각, 혁명예술, 급여명세서, 잡담, 금강트레킹, 투자주의, 흔적\n",
      "Nearest to 교육: 부모, 아이, 수업, 아랫니, 사교육, 윤리교사, 자녀교육, 곰곰이\n",
      "Nearest to 취업: 면접, 취업준비, 채용, 이직, 이력서, 진로, 스펙, 구직\n",
      "Nearest to 마케팅: 광고, 디지털마케팅, 브랜드, 전략, 스타트업, 고객, 브랜딩, 마케팅전략\n",
      "Nearest to 방송: MBC, 콘텐츠, 예능, 김태근, 작동, 넷플릭스, 언론, 진성리더십\n",
      "Nearest to 감성에세이: 공감에세이, 사랑, 감성작가, 이동영, 에세이, 인간관계, 감성, 이별\n",
      "Nearest to 하이에나: 힌트, 여행만화, 기온거리, 어깨충돌증후군, 인생캠프, 몽골일상, 비상연락처, 패트리어트\n",
      "Nearest to 버스: 지하철, 출근, 대중교통, 출근길, 출퇴근, 거리, 운전, 휴가\n",
      "Nearest to 행복: 황태영, 마음, 두려움, 존재, 인생캠프, 자신, 외로움, 바라본세상\n",
      "Nearest to 빵가게: SK와이번스, 아이, 녹두서평, 메밀, 조카, 소리, 간장감자조림, 비치타올\n",
      "Average loss at step 810000 : 2.2095548379421235\n",
      "Average loss at step 820000 : 2.19757971534729\n",
      "Average loss at step 830000 : 2.1902623594909905\n",
      "Average loss at step 840000 : 2.19048346657753\n",
      "Average loss at step 850000 : 2.188477606076002\n",
      "Average loss at step 860000 : 2.1925283290714024\n",
      "Average loss at step 870000 : 2.1801978992760183\n",
      "Average loss at step 880000 : 2.1827388018757103\n",
      "Average loss at step 890000 : 2.1903222093999384\n",
      "Average loss at step 900000 : 2.2034019629597665\n",
      "Nearest to 출판: 출판사, 출간, 작가, 원고, 독립출판, 편집자, 우지, 셀프출판\n",
      "Nearest to 아이돌: 대중음악, 음악리뷰, 케이팝, 아이유, 걸그룹, 앨범, 음악추천, 방탄소년단\n",
      "Nearest to 생각: 양악, 습관, 자신, 선택, 창조루틴, 재미, 이유, 황태영\n",
      "Nearest to 사회복지사: 사회복지, 이지훈기자, 교육강좌, 송정, 정배리, 이미지세상, 과학소통, 천문대\n",
      "Nearest to 방송연예: 음악사, 비폭력운동, 첩보, 퇴장, 숫돌, 수사관, 급식소, 에밀졸라\n",
      "Nearest to 부동산경매변호사: 진실, 공연예술, 녹차콜라, 제인오스틴, 꼬리, 물총새, 에바항공, 혐오\n",
      "Nearest to 단상: 장기연애, 잡담, 혁명예술, 신발박물관, 일기, 핸디선풍기, 비어바이크, 어른\n",
      "Nearest to 교육: 수업, 아이, 휘트니, 사교육, 교육과정, 비밀친구, 철판볶음, 윤리교사\n",
      "Nearest to 취업: 면접, 이력서, 이직, 스펙, 취업준비, 채용, 자소서, 진로\n",
      "Nearest to 마케팅: 브랜드, 마케터, 디지털마케팅, SNS, 고객, 스타트업, 마케팅전략, 영업\n",
      "Nearest to 방송: MBC, 콘텐츠, 작동, 김태근, 예능, 진성리더십, 넷플릭스, 김양희\n",
      "Nearest to 감성에세이: 감성, 스트라바, 공감에세이, 캘리그라피, 황태영, 감성유나, 홍시홍시, 와이브로\n",
      "Nearest to 하이에나: 힌트, 여행만화, 유럽여행, 기온거리, 어깨충돌증후군, 뉴질랜드, 인생캠프, 몽골일상\n",
      "Nearest to 버스: 지하철, 대중교통, 출근, 일본공예업계, 거리, 운전, 출근길, 택시\n",
      "Nearest to 행복: 인생, 관계, 존재, 마음, 과정, 황태영, 휴식, 자신\n",
      "Nearest to 빵가게: SK와이번스, 녹두서평, 조카, 메밀, 간장감자조림, 소리, 비치타올, 회계보고\n",
      "Average loss at step 910000 : 2.1896287739872933\n",
      "Average loss at step 920000 : 2.230344821032882\n",
      "Average loss at step 930000 : 2.200899818587303\n",
      "Average loss at step 940000 : 2.1762466095149517\n",
      "Average loss at step 950000 : 2.164287307667732\n",
      "Average loss at step 960000 : 2.1743709537386895\n",
      "Average loss at step 970000 : 2.1522030547857285\n",
      "Average loss at step 980000 : 2.156195363688469\n",
      "Average loss at step 990000 : 2.146467219120264\n",
      "Average loss at step 1000000 : 2.1389520821750163\n",
      "Nearest to 출판: 출간, 출판사, 독립출판, 원고, 작가, 편집자, 제이지, 글짓는사람\n",
      "Nearest to 아이돌: 대중음악, 케이팝, 음악리뷰, 앨범, 걸그룹, 방탄소년단, 아이유, 음반\n",
      "Nearest to 생각: 자신, 당신, 우리, 황태영, 시작, 이유, 이해, 세상\n",
      "Nearest to 사회복지사: 사회복지, 이지훈기자, 교육강좌, 청춘투자, 이미지세상, 정배리, 과학소통, 송정\n",
      "Nearest to 방송연예: 음악사, 비폭력운동, 첩보, 퇴장, 숫돌, 에밀졸라, 연극, 급식소\n",
      "Nearest to 부동산경매변호사: 녹차콜라, 공연예술, 제인오스틴, 진실, 꼬리, 에바항공, 물총새, 통영라이더\n",
      "Nearest to 단상: 일기, 착각, 생각, 창업멤버, 공감문구, 지옥사원, 일상, 내일\n",
      "Nearest to 교육: 초등학교, 수업, 윤리교사, 부모, 아이, 개학, 교육과정, 카메라렌즈로\n",
      "Nearest to 취업: 면접, 취업준비, 스펙, 채용, 구직, 이력서, 진로, 이직\n",
      "Nearest to 마케팅: 브랜드, 광고, 디지털마케팅, 고객, 전략, 해외산업, 건륭제, 마케팅전략\n",
      "Nearest to 방송: MBC, 콘텐츠, 예능, 프로듀서, 작동, 김태근, TV, 진성리더십\n",
      "Nearest to 감성에세이: 일상에세이, 오지호, 걷기예찬, 퇴사, 사랑, 스트라바, 공감에세이, 오일나우\n",
      "Nearest to 하이에나: 힌트, 여행만화, 기온거리, 어깨충돌증후군, 인생캠프, 몽골일상, react, 지방소멸\n",
      "Nearest to 버스: 지하철, 대중교통, 거리, 출근길, 일본공예업계, 운전, 핑계, 친구\n",
      "Nearest to 행복: 자신, 황태영, 열정, 당신, 육아, 친구, 우리, 고민\n",
      "Nearest to 빵가게: SK와이번스, 아이, 메밀, 녹두서평, 간장감자조림, 비치타올, 조카, 위로\n"
     ]
    }
   ],
   "source": [
    "# Step 5: skip-gram 모델 학습\n",
    "# 4시 4분 시작\n",
    "num_steps = 1000001\n",
    "data = corpus\n",
    "ordered_words = list(word_to_id.keys())\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    average_loss, data_index = 0, 0\n",
    "    for step in range(num_steps):\n",
    "        batch_inputs, batch_labels, data_index = generate_batch(data, batch_size, num_skips, skip_window, data_index)\n",
    "\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "        _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "\n",
    "        # 마지막 10000번에 대한 평균 loss 표시\n",
    "        if step % 10000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 10000\n",
    "            print('Average loss at step {} : {}'.format(step, average_loss))\n",
    "            average_loss = 0\n",
    "        \n",
    "        # 10만번째마다 valid size만큼 sim 계산\n",
    "        if step % 100000 == 0:\n",
    "            sim = similarity.eval()         # (16, vocab_size)\n",
    "\n",
    "            for i in range(valid_size):\n",
    "                valid_word = ordered_words[valid_examples[i]]\n",
    "\n",
    "                top_k = 8\n",
    "                nearest = sim[i].argsort()[-top_k - 1:-1][::-1]\n",
    "                log_str = ', '.join([ordered_words[k] for k in nearest])\n",
    "                print('Nearest to {}: {}'.format(valid_word, log_str))\n",
    "\n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(session,'keyword_embedding_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96864, 128)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(final_embeddings.shape)\n",
    "print(type(final_embeddings))\n",
    "np.save(directory+'keyword_embedding_matrix',final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "atc = metadata.copy()\n",
    "atc['reg_datetime'] = atc['reg_ts'].apply(lambda x : datetime.fromtimestamp(x/1000.0))\n",
    "atc.loc[atc['reg_datetime'] == atc['reg_datetime'].min(), 'reg_datetime'] = datetime(2090, 12, 31)\n",
    "atc['reg_dt'] = atc['reg_datetime'].dt.date\n",
    "atc['type'] = atc['magazine_id'].apply(lambda x : '개인' if x == 0.0 else '매거진')\n",
    "# 컬럼명 변경\n",
    "atc.columns = ['id', 'display_url', 'article_id', 'keyword_list', 'magazine_id', 'reg_ts', 'sub_title', 'title', 'author_id', 'reg_datetime', 'reg_dt', 'type']\n",
    "atc.head()\n",
    "atc_cnt_by_reg_dt = atc.groupby('reg_dt', as_index=False)['article_id'].count()\n",
    "read_file_lst = glob.glob(directory + 'read/read/*')\n",
    "exclude_file_lst = ['read.tar']\n",
    "read_df_lst = []\n",
    "for f in read_file_lst:\n",
    "    file_name = os.path.basename(f)\n",
    "    if file_name in exclude_file_lst:\n",
    "        print(file_name)\n",
    "    else:\n",
    "        df_temp = pd.read_csv(f, header=None, names=['raw'])\n",
    "        df_temp['dt'] = file_name[:8]\n",
    "        df_temp['hr'] = file_name[8:10]\n",
    "        df_temp['user_id'] = df_temp['raw'].str.split(' ').str[0]\n",
    "        df_temp['article_id'] = df_temp['raw'].str.split(' ').str[1:].str.join(' ').str.strip()\n",
    "        read_df_lst.append(df_temp)\n",
    "        \n",
    "read = pd.concat(read_df_lst)\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(' ')))\n",
    "read_cnt_by_user = read['article_id'].str.split(' ').map(len)\n",
    "read_raw = pd.DataFrame({'dt': np.repeat(read['dt'], read_cnt_by_user),\n",
    "                         'hr': np.repeat(read['hr'], read_cnt_by_user),\n",
    "                         'user_id': np.repeat(read['user_id'], read_cnt_by_user),\n",
    "                         'article_id': chainer(read['article_id'])})\n",
    "read_raw.shape\n",
    "atc_read_cnt = read_raw[read_raw.article_id != ''].groupby('article_id')['user_id'].count()\n",
    "atc_read_cnt = atc_read_cnt.reset_index()\n",
    "atc_read_cnt.columns = ['article_id', 'read_cnt']\n",
    "#metadata 결합\n",
    "atc_read_cnt = pd.merge(atc_read_cnt, atc, how='left', left_on='article_id', right_on='article_id')\n",
    "# metadata를 찾을 수 없는 소비 로그 제외\n",
    "atc_read_cnt_nn = atc_read_cnt[atc_read_cnt['id'].notnull()]\n",
    "# 소비수 기준 분류값\n",
    "def get_class(x):\n",
    "    if x >= 142:\n",
    "        result = '5%'\n",
    "    elif x >= 72:\n",
    "        result = '10%'\n",
    "    elif x >= 25:\n",
    "        result = '25%'\n",
    "    elif x >= 8:\n",
    "        result = '50%'\n",
    "    elif x >= 3:\n",
    "        result = '75%'\n",
    "    else:\n",
    "        result = '100%'\n",
    "    return result\n",
    "\n",
    "atc_read_cnt_nn['class'] = atc_read_cnt_nn['read_cnt'].map(get_class)\n",
    "#atc_read_cnt_nn.sort_values(by='read_cnt', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_top_50000 = atc_read_cnt_nn.sort_values(by='read_cnt', ascending=False)[:50000]\n",
    "a = 20190222\n",
    "a = pd.to_datetime(a,format='%Y%m%d')\n",
    "c = 20901231\n",
    "c = pd.to_datetime(c,format='%Y%m%d')\n",
    "article_20190222_20190301 = atc_read_cnt_nn[atc_read_cnt_nn['reg_datetime'] >= a]\n",
    "article_20190222_20190301 = article_20190222_20190301[article_20190222_20190301['reg_datetime'] != c]\n",
    "recent_top_5000 = article_20190222_20190301.sort_values(by='read_cnt',ascending=False)[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23821"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 20190301\n",
    "b = pd.to_datetime(b,format='%Y%m%d')\n",
    "article_20190301_20190314 = atc[atc['reg_datetime'] >= b]\n",
    "article_20190301_20190314 = article_20190301_20190314[article_20190301_20190314['reg_datetime'] != c]\n",
    "len(article_20190301_20190314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_top_50000.to_csv(directory+'total_top_50000.csv',encoding='utf-8')\n",
    "recent_top_5000.to_csv(directory+'recent_top_5000.csv',encoding='utf-8')\n",
    "article_20190222_20190301.to_csv(directory+'article_20190222_20190301.csv',encoding='utf-8')\n",
    "article_20190301_20190314.to_csv(directory+'article_20190301_20190314.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 읽을때는 아래와 같이\n",
    "user_df = pd.read_csv(directory+'user_df.csv')\n",
    "user_df = user_df.drop('Unnamed: 0',1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(directory+'user_df.csv')\n",
    "user_df = user_df.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526557"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df['read_cnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_read_articles = set()\n",
    "for x in user_df['read_articles']:\n",
    "    x_li = ast.literal_eval(x)\n",
    "    for y in x_li:\n",
    "        user_read_articles.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = final_embeddings[1]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vector = np.zeros(shape=(128,),dtype='float32')\n",
    "type(user_vector)\n",
    "user_vector.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = user_df['id'].tolist()\n",
    "user_visit_cnt = user_df['visit_cnt'].tolist()\n",
    "user_read_cnt = user_df['read_cnt'].tolist()\n",
    "user_read_articles = user_df['read_articles'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_read_articles)):\n",
    "    x_li = ast.literal_eval(user_read_articles[i])\n",
    "    user_read_articles[i] = x_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix = np.zeros(shape=(3000,128),dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-15ed33cd558b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "final_embeddings[word_to_id[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_list = user_read_articles[0]\n",
    "article_id = read_list[0]\n",
    "k = metadata[metadata['id'] == article_id][0:1]\n",
    "key_list = list(k['keyword_list'])[0]\n",
    "magazine_id = list(k['magazine_id'])[0]\n",
    "key_list\n",
    "magazine_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magazine_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(magazine[magazine['id'] == 0]['magazine_tag_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((list(magazine[magazine['id'] == 0]['magazine_tag_list']))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_list_len = []\n",
    "for i in range(3000):\n",
    "    read_list_len.append(len(user_read_articles[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random.choices(read_list_len,k=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "progress:   0%|                                                                               | 0/3000 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "progress:   0%|▎                                                                   | 15/3000 [02:04<6:53:54,  8.32s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   0%|▎                                                                   | 15/3000 [02:21<6:53:54,  8.32s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   1%|▌                                                                   | 24/3000 [04:06<8:10:15,  9.88s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   1%|▌                                                                   | 24/3000 [04:22<8:10:15,  9.88s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   1%|▊                                                                   | 38/3000 [06:25<8:08:21,  9.89s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   1%|▊                                                                   | 38/3000 [06:43<8:08:21,  9.89s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   2%|█                                                                   | 49/3000 [08:37<8:37:20, 10.52s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   2%|█                                                                   | 49/3000 [08:54<8:37:20, 10.52s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   2%|█▎                                                                  | 59/3000 [10:38<8:59:10, 11.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   2%|█▎                                                                  | 59/3000 [10:55<8:59:10, 11.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   2%|█▌                                                                  | 68/3000 [12:40<9:34:40, 11.76s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   2%|█▌                                                                  | 68/3000 [12:56<9:34:40, 11.76s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   3%|█▉                                                                  | 83/3000 [14:54<8:51:07, 10.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   3%|█▉                                                                  | 83/3000 [15:07<8:51:07, 10.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   3%|██                                                                 | 91/3000 [17:12<10:20:36, 12.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   3%|██                                                                 | 91/3000 [17:28<10:20:36, 12.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   4%|██▍                                                                | 109/3000 [19:31<9:03:22, 11.28s/it]\n",
      "\n",
      "\n",
      "\n",
      "progress:   4%|██▍                                                                | 109/3000 [19:49<9:03:22, 11.28s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-225-cebbbbe40edf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0marticle_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0marticle_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mkey_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keyword_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmagazine_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'magazine_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len(user_read_articles) \n",
    "# unique한 article 수는 약 17만개를 읽음 (3천명이 읽은 글들 중)\n",
    "\n",
    "user_matrix = np.zeros(shape=(3000,128),dtype = 'float32')\n",
    "\n",
    "for i in tqdm(range(3000),desc='progress',mininterval=120):\n",
    "    user_vector = np.zeros(shape=(128,),dtype='float32')\n",
    "    user = user_id[i]\n",
    "    read_list = user_read_articles[i]\n",
    "    if(len(read_list) > 200):\n",
    "        read_list = random.choices(read_list,k=200)\n",
    "    cnt = 0\n",
    "    for article_id in read_list:\n",
    "        k = metadata[metadata['id'] == article_id][0:1]\n",
    "        key_list = list(k['keyword_list'])[0]\n",
    "        magazine_id = list(k['magazine_id'])[0]\n",
    "        \n",
    "        if len(key_list) != 0 :\n",
    "            for word in key_list :\n",
    "                user_vector += final_embeddings[word_to_id[word]]\n",
    "                cnt +=1\n",
    "        if magazine_id != 0:\n",
    "            mag_list = list(magazine[magazine['id'] == magazine_id]['magazine_tag_list'])\n",
    "            if len(mag_list) != 0:\n",
    "                if len(mag_list[0]) != 0:\n",
    "                    for word in mag_list[0]:\n",
    "                        user_vector += final_embeddings[word_to_id[word]]\n",
    "                        cnt+=1\n",
    "    if(cnt != 0):\n",
    "        user_vector /= cnt\n",
    "    user_matrix[i] = user_vector\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = user_df['read_articles'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@yellowduck_64',\n",
       " '@yellowduck_63',\n",
       " '@minigorae_240',\n",
       " '@minigorae_179',\n",
       " '@minigorae_183',\n",
       " '@minigorae_256',\n",
       " '@minigorae_236',\n",
       " '@minigorae_249',\n",
       " '@minigorae_239',\n",
       " '@jiholim_82',\n",
       " '@minigorae_245',\n",
       " '@minigorae_235',\n",
       " '@minigorae_242',\n",
       " '@minigorae_243',\n",
       " '@minigorae_248',\n",
       " '@minigorae_244',\n",
       " '@minigorae_233',\n",
       " '@brunch_141',\n",
       " '@imaudio_39',\n",
       " '@egg0001_132',\n",
       " '@masism_334',\n",
       " '@minigorae_237',\n",
       " '@minigorae_254',\n",
       " '@minigorae_255',\n",
       " '@minigorae_246',\n",
       " '@sdain-sygang_29',\n",
       " '@minigorae_234',\n",
       " '@minigorae_258',\n",
       " '@minigorae_252',\n",
       " '@minigorae_257',\n",
       " '@minigorae_238',\n",
       " '@minigorae_241',\n",
       " '@minigorae_253',\n",
       " '@minigorae_247',\n",
       " '@minigorae_250']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "a_li = ast.literal_eval(a)\n",
    "a_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5000\n",
      "5189\n",
      "23821\n"
     ]
    }
   ],
   "source": [
    "print(len(total_top_50000))\n",
    "print(len(recent_top_5000))\n",
    "print(len(article_20190222_20190301))\n",
    "print(len(article_20190301_20190314))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>read_cnt</th>\n",
       "      <th>id</th>\n",
       "      <th>display_url</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>reg_datetime</th>\n",
       "      <th>reg_dt</th>\n",
       "      <th>type</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63061</th>\n",
       "      <td>@brunch_141</td>\n",
       "      <td>97206</td>\n",
       "      <td>141.0</td>\n",
       "      <td>https://brunch.co.kr/@brunch/141</td>\n",
       "      <td>[브런치X빨강머리앤, 빨강머리앤, 출판, 작가]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.539742e+12</td>\n",
       "      <td>글·그림 작가 파트너 프로젝트</td>\n",
       "      <td>브런치 작가가 함께 빨강머리 앤을 그리고 쓰다.</td>\n",
       "      <td>@brunch</td>\n",
       "      <td>2018-10-17 11:11:22</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>개인</td>\n",
       "      <td>5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id  read_cnt     id                       display_url  \\\n",
       "63061  @brunch_141     97206  141.0  https://brunch.co.kr/@brunch/141   \n",
       "\n",
       "                     keyword_list  magazine_id        reg_ts  \\\n",
       "63061  [브런치X빨강머리앤, 빨강머리앤, 출판, 작가]          0.0  1.539742e+12   \n",
       "\n",
       "              sub_title                       title author_id  \\\n",
       "63061  글·그림 작가 파트너 프로젝트  브런치 작가가 함께 빨강머리 앤을 그리고 쓰다.   @brunch   \n",
       "\n",
       "             reg_datetime      reg_dt type class  \n",
       "63061 2018-10-17 11:11:22  2018-10-17   개인    5%  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_top_50000[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643104"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: embeddings 시각화\n",
    "\n",
    "def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "\n",
    "    plt.figure(figsize=(18, 18))        # in inches\n",
    "\n",
    "    for (x, y), label in zip(low_dim_embs, labels):\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "\n",
    "    plt.savefig(filename)\n",
    "\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "\n",
    "    plot_only = 500\n",
    "    low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only])     # (500, 2)\n",
    "    labels = ordered_words[:plot_only]                                  # 재구성한 코드\n",
    "\n",
    "    plot_with_labels(low_dim_embs, labels)\n",
    "\n",
    "except ImportError:\n",
    "    print('Please install sklearn, matplotlib, and scipy to show embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 단어들 뽑혔는지 확인\n",
    "li = []\n",
    "for key in word_to_id:\n",
    "    li.append(key)\n",
    "li_pd = pd.DataFrame(li)\n",
    "li_pd.to_csv(directory+'li_pd.csv',encoding='ms949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료들\n",
    "\n",
    "- python list : https://www.w3schools.com/python/python_ref_list.asp\n",
    "- 한국어 어휘 list : https://www.korean.go.kr/front/etcData/etcDataView.do?mn_id=46&etc_seq=71\n",
    "- pandas to csv : https://mjdeeplearning.tistory.com/41\n",
    "- dict to pandas : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_dict.html\n",
    "- dict to list : https://stackoverflow.com/questions/1679384/converting-dictionary-to-list\n",
    "- for dict : https://wikidocs.net/16043\n",
    "- list to dict : https://thispointer.com/python-pandas-how-to-convert-lists-to-a-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Gram 구현시 참고자료\n",
    "- 원본 코드 : https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/word2vec/word2vec_basic.py // 원본 코드\n",
    "- 설명 글 : https://github.com/YBIGTA/Deep_learning/blob/master/RNN/nlp/%EA%B5%AC%ED%98%84/skip-gram%20with%20tensorflow.md // 설명 불충분\n",
    "    \n",
    "- 완전 꼼꼼한 설명 글 : https://pythonkim.tistory.com/93 (매우 꼼꼼 +++)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "- model save  : https://goodtogreate.tistory.com/entry/Saving-and-Restoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "- save, load : https://rfriend.tistory.com/358\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1932817184,         317,         116,          99,         104,\n",
       "               317, -1288904656,         317])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = np.ndarray(shape=(8), dtype=np.int32)\n",
    "labels = np.ndarray(shape=(8, 1), dtype=np.int32)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
