{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta, datetime\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "directory = 'D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/'\n",
    "font_path = directory + 'NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path, size=10).get_name()\n",
    "plt.rc('font', family=font_name, size=12)\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14s\n",
    "metadata = pd.read_json(directory + 'metadata.json', lines=True)\n",
    "magazine = pd.read_json(directory + 'magazine.json', lines=True)\n",
    "users = pd.read_json(directory + 'users.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article_csv Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15165"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "total_top_50000 = pd.read_csv(directory+'total_top_50000.csv')\n",
    "total_top_50000 = total_top_50000.drop('Unnamed: 0',1)\n",
    "recent_top_5000 = pd.read_csv(directory+'recent_top_5000.csv')\n",
    "recent_top_5000 = recent_top_5000.drop('Unnamed: 0',1)\n",
    "article_20190222_20190301 = pd.read_csv(directory+'article_20190222_20190301.csv')\n",
    "article_20190222_20190301 = article_20190222_20190301.drop('Unnamed: 0',1)\n",
    "article_20190301_20190314 = pd.read_csv(directory+'article_20190301_20190314.csv')\n",
    "article_20190301_20190314 = article_20190301_20190314.drop('Unnamed: 0',1)\n",
    "\n",
    "article_20190222_20190314 = article_20190222_20190301.append(article_20190301_20190314)\n",
    "article_20190222_20190314['reg_datetime']  = article_20190222_20190314['reg_datetime'].map(lambda x : pd.to_datetime(x,format='%Y-%m-%d'))\n",
    "# 20190314 보다 큰 건 제외\n",
    "a = 20190314\n",
    "a = pd.to_datetime(a,format='%Y%m%d')\n",
    "article_20190222_20190314 = article_20190222_20190314[article_20190222_20190314['reg_datetime'] <= a]\n",
    "article_20190222_20190314 = article_20190222_20190314.sort_values('reg_datetime')\n",
    "len(article_20190222_20190314)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "popular_20190201_20190301_10 = pd.read_csv(directory+'popular_20190201_20190301_10.csv')\n",
    "popular_20190201_20190301_10 = popular_20190201_20190301_10.drop('Unnamed: 0',1)\n",
    "popular_20190201_20190301_10[:1]\n",
    "popular_20190201_20190301_10['reg_datetime']  = popular_20190201_20190301_10['reg_datetime'].map(lambda x : pd.to_datetime(x,format='%Y-%m-%d'))\n",
    "popular_20190201_20190301_10['keyword_list']  = popular_20190201_20190301_10['keyword_list'].map(lambda x : ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_total_matrix_1 = np.load(directory+'article_total_matrix.npy')\n",
    "article_20190222_20190314_matrix_1 = np.load(directory+'article_20190222_20190314_matrix.npy')\n",
    "popular_20190201_20190301_10_matrix_1 = np.load(directory+'popular_20190201_20190301_10_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643104, 128)\n",
      "(15165, 128)\n",
      "(55734, 128)\n"
     ]
    }
   ],
   "source": [
    "print(article_total_matrix_1.shape)\n",
    "print(article_20190222_20190314_matrix_1.shape)\n",
    "print(popular_20190201_20190301_10_matrix_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User_df load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_users_path ='D:/ANACONDA/envs/tf-gpu/code/NLP/kakao/data/predict/predict/dev.users'\n",
    "dev_users_list = []\n",
    "with open(dev_users_path, 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "    #print(len(lines))\n",
    "    #print(type(lines))\n",
    "    dev_users_list = lines\n",
    "    del lines\n",
    "for i in range(len(dev_users_list)):\n",
    "    dev_users_list[i] = dev_users_list[i].replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "user_df = pd.read_csv(directory+'user_df.csv')\n",
    "user_df = user_df.drop('Unnamed: 0',1)\n",
    "user_df['read_articles'] = user_df['read_articles'].map(lambda x : ast.literal_eval(x))\n",
    "print(len(user_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "user_id = user_df['id'].tolist()\n",
    "user_visit_cnt = user_df['visit_cnt'].tolist()\n",
    "user_read_cnt = user_df['read_cnt'].tolist()\n",
    "user_read_articles = user_df['read_articles'].tolist()\n",
    "user_isNew =[]\n",
    "for i in range(len(user_id)):\n",
    "    if(user_read_cnt[i] <= 5):\n",
    "        user_isNew.append(1)\n",
    "    else:\n",
    "        user_isNew.append(0)\n",
    "\n",
    "# 1:34 ~ 1:35\n",
    "user_following_list = []\n",
    "for i in range(len(user_id)):\n",
    "    li =list(users[users['id'] == user_id[i]]['following_list'])\n",
    "    if(len(li) != 0):\n",
    "        user_following_list.append(li[0])\n",
    "    else:\n",
    "        user_following_list.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|████████████████████████████████████████████████████████████████████| 3000/3000 [05:51<00:00,  8.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2mins\n",
    "following_article_list = []\n",
    "for i in tqdm(range(3000),desc='progress',mininterval=20):\n",
    "    fl = user_following_list[i]\n",
    "    if(len(fl) > 200):\n",
    "        fl = random.choices(fl,k=200)\n",
    "    if(len(fl) != 0):\n",
    "        following_articles = []\n",
    "        for author in fl:\n",
    "            following_articles += popular_20190201_20190301_10[popular_20190201_20190301_10['author_id'] == author]['article_id'].tolist()\n",
    "        following_article_list.append(following_articles)\n",
    "    else :\n",
    "        following_article_list.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_20190201_20190301_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3000, 128)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "user_matrix_1 = np.load(directory+'user_matrix.npy')\n",
    "print(type(user_matrix_1))\n",
    "print(user_matrix_1.shape)\n",
    "print(user_matrix_1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x,y,eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2))+eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2))+eps)\n",
    "    return np.dot(nx,ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_noraml_algo(idx, num_total, num_recent, num_following, num_keyword):\n",
    "    \n",
    "    recommend_total = []\n",
    "    if(num_total > 0):\n",
    "        cnt = 0\n",
    "        i = 0\n",
    "        while(cnt < 100):\n",
    "            artic = list(total_top_50000[i:i+1]['article_id'])[0]\n",
    "            if artic not in user_read_articles[idx]:\n",
    "                recommend_total.append(artic)\n",
    "                cnt+=1\n",
    "            i+= 1\n",
    "            if(i>50000):\n",
    "                break\n",
    "    \n",
    "    recommend_recent = []\n",
    "    if(num_recent > 0):\n",
    "        cnt = 0\n",
    "        i = 0\n",
    "        while(cnt < 100):\n",
    "            artic = list(popular_20190201_20190301_10[i:i+1]['article_id'])[0]\n",
    "            if artic not in user_read_articles[idx]:\n",
    "                recommend_recent.append(artic)\n",
    "                cnt+=1\n",
    "            i +=1\n",
    "            if(i >5000):\n",
    "                break\n",
    "        \n",
    "    recommend_following = []\n",
    "    if(num_following > 0):\n",
    "        following_cnt = 0\n",
    "        article_list = following_article_list[idx]\n",
    "        if(len(article_list) != 0):\n",
    "            random.shuffle(article_list)\n",
    "            for artic in article_list:\n",
    "                if artic not in user_read_articles[idx]:\n",
    "                    recommend_following.append(artic)\n",
    "                    following_cnt+=1\n",
    "                if(following_cnt > 100):\n",
    "                    break\n",
    "    \n",
    "    recommend_keyword = []\n",
    "    if(num_keyword > 0):\n",
    "        user_vector_x = user_matrix_1[idx]\n",
    "        cos_sim = []\n",
    "\n",
    "        for i in range(len(popular_20190201_20190301_10_matrix_1)):\n",
    "            cos_sim.append(cos_similarity(user_vector_x,popular_20190201_20190301_10_matrix_1[i]))\n",
    "        top_k = 1000\n",
    "        cos_s = np.asarray(cos_sim)\n",
    "        cos_sim = cos_s.argsort()[-top_k -1 : -1][::-1].tolist()\n",
    "        cnt = 0\n",
    "        for i in range(1000):\n",
    "            artic = list(popular_20190201_20190301_10[cos_sim[i]:cos_sim[i]+1]['article_id'])[0]\n",
    "            if artic not in user_read_articles[idx]: \n",
    "                recommend_keyword.append(list(popular_20190201_20190301_10[cos_sim[i]:cos_sim[i]+1]['article_id'])[0])\n",
    "                cnt+=1\n",
    "            if cnt >= 100 :\n",
    "                break\n",
    "    \n",
    "    return recommend_total, recommend_recent, recommend_following, recommend_keyword\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_total, recommend_recent, recommend_following, recommend_keyword = recommend_noraml_algo(0,30,30,40,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_new = ''\n",
    "for x in recommend_recent:\n",
    "    recommend_new += ' ' + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio 변경하면서 결과 비교\n",
    "- ratio1 : 각각 성능이 얼마나 나오는지 비교해보기\n",
    "- ratio2 \n",
    "- ratio3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:55<00:00, 53.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3000/3000 [1:07:44<00:00,  1.35s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [02:24<00:00, 20.81it/s]\n",
      " 18%|█████████████▌                                                               | 528/3000 [12:27<1:01:49,  1.50s/it]"
     ]
    }
   ],
   "source": [
    "ratio1 =[[0,100,0,0],[0,0,0,100],[50,50,0,0],[10,50,0,40]]\n",
    "# hyperparameter\n",
    "for ratio in ratio1:\n",
    "    num_total = ratio[0]\n",
    "    num_recent = ratio[1]\n",
    "    num_following = ratio[2]\n",
    "    num_keyword = ratio[3]\n",
    "    hyp = str(num_total)+'_'+str(num_recent)+'_' + str(num_following)+'_' + str(num_keyword)\n",
    "    try:\n",
    "        if not(os.path.isdir(directory + hyp )):\n",
    "            os.makedirs(os.path.join(directory + hyp))\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise\n",
    "\n",
    "    with open(directory + hyp +'/recommend' + '.txt','w') as file:\n",
    "        for i in tqdm(range(len(user_df)),mininterval=20):\n",
    "            uid = dev_users_list[i]\n",
    "            i = user_id.index(uid)\n",
    "            uid = user_id[i]\n",
    "            isNew = user_isNew[i]\n",
    "            if(isNew == 1):\n",
    "            # 신규 회원\n",
    "                file.write(uid + recommend_new)\n",
    "                file.write('\\n')\n",
    "            else:\n",
    "            # 기존 회원\n",
    "                # 함수\n",
    "                # list로 반환\n",
    "                # hyperparmeter 비율 정해서 반환 (str 형태로)\n",
    "                recommend_total, recommend_recent, recommend_following, recommend_keyword = recommend_noraml_algo(i,num_total,num_recent,num_following,num_keyword)\n",
    "                recommend_total = recommend_total[:num_total]\n",
    "                recommend_recent = recommend_recent[:num_recent]\n",
    "                if( num_following > len(recommend_following)):\n",
    "                    num_following = len(recommend_following)\n",
    "                recommend_following = recommend_following[:num_following]\n",
    "                recommend_keyword = recommend_keyword[:num_keyword]\n",
    "\n",
    "                # 골고루 합치기 \n",
    "                f_i=0\n",
    "                k_i=0\n",
    "                recommend_f_k = []\n",
    "                for cnt_fk in range(num_following + num_keyword):\n",
    "                    if f_i < num_following:\n",
    "                        recommend_f_k.append(recommend_following[f_i])\n",
    "                        f_i+=1\n",
    "                    if k_i < num_keyword:\n",
    "                        recommend_f_k.append(recommend_keyword[k_i])\n",
    "                        k_i+=1\n",
    "\n",
    "                recommend_r_t = []\n",
    "                r_i = 0\n",
    "                t_i = 0\n",
    "                for cnt_rt in range(num_recent+num_total):\n",
    "                    if r_i < num_recent:\n",
    "                        recommend_r_t.append(recommend_recent[r_i])\n",
    "                        r_i += 1\n",
    "\n",
    "                    if t_i < num_total:\n",
    "                        recommend_r_t.append(recommend_total[t_i])\n",
    "                        t_i += 1\n",
    "\n",
    "                cnt_rt = len(recommend_r_t)\n",
    "                rt_i = 0\n",
    "                cnt_fk = len(recommend_f_k)\n",
    "                fk_i = 0\n",
    "                recommend_all = []\n",
    "                for cnt in range(cnt_fk + cnt_rt):\n",
    "                    if(rt_i < cnt_rt):\n",
    "                        recommend_all.append(recommend_r_t[rt_i])\n",
    "                        rt_i +=1\n",
    "                    if(fk_i < cnt_fk):\n",
    "                        recommend_all.append(recommend_f_k[fk_i])\n",
    "                        fk_i +=1\n",
    "                recommend_all = set(recommend_all)\n",
    "                # 부족한 경우 recent 에서\n",
    "                if(len(recommend_all) < 100):\n",
    "                    ar_id = 0\n",
    "                    while(len(recommend_all) != 100):\n",
    "                        artic = list(popular_20190201_20190301_10[ar_id:ar_id+1]['article_id'])[0]\n",
    "                        if artic not in user_read_articles[i]:\n",
    "                            recommend_all.add(artic)\n",
    "                        ar_id +=1\n",
    "                # 들어가는거 중복 제거 안해준것 같은데...\n",
    "                \n",
    "                recommend_all = list(recommend_all)\n",
    "                # 마지막 최종 output\n",
    "                recommend_normal = ''\n",
    "                for x in recommend_all:\n",
    "                    recommend_normal += ' '+ x\n",
    "\n",
    "                file.write(uid + recommend_normal)\n",
    "                file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity 계산\n",
    "\n",
    "- user_matrix_1 (3000,128)\n",
    "- article_20190222_20190314_matrix_1 (15---,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x,y,eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2))+eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2))+eps)\n",
    "    return np.dot(nx,ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm(range(3000),desc='progress',mininterval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 643104/643104 [00:17<00:00, 36331.67it/s]\n"
     ]
    }
   ],
   "source": [
    "user_vector_x = user_matrix_1[0]\n",
    "cos_sim = []\n",
    "    \n",
    "for i in tqdm(range(len(article_total_matrix_1)),mininterval=10):\n",
    "    cos_sim.append(cos_similarity(user_vector_x,article_total_matrix_1[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 15165/15165 [00:00<00:00, 36250.96it/s]\n"
     ]
    }
   ],
   "source": [
    "user_vector_x = user_matrix_1[0]\n",
    "cos_sim = []\n",
    "    \n",
    "for i in tqdm(range(len(article_20190222_20190314_matrix_1)),mininterval=10):\n",
    "    cos_sim.append(cos_similarity(user_vector_x,article_20190222_20190314_matrix_1[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91977626"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim[2207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12246,\n",
       " 2207,\n",
       " 1210,\n",
       " 12685,\n",
       " 5499,\n",
       " 9893,\n",
       " 9299,\n",
       " 7146,\n",
       " 8050,\n",
       " 11179,\n",
       " 13911,\n",
       " 10802,\n",
       " 2615,\n",
       " 13885,\n",
       " 6367,\n",
       " 13901,\n",
       " 6134,\n",
       " 1930,\n",
       " 10826,\n",
       " 2192,\n",
       " 2324,\n",
       " 6480,\n",
       " 13086,\n",
       " 2956,\n",
       " 8431,\n",
       " 7809,\n",
       " 2999,\n",
       " 4321,\n",
       " 10867,\n",
       " 7300,\n",
       " 5093,\n",
       " 4787,\n",
       " 5236,\n",
       " 535,\n",
       " 14201,\n",
       " 13383,\n",
       " 12359,\n",
       " 8927,\n",
       " 176,\n",
       " 11606,\n",
       " 5326,\n",
       " 1857,\n",
       " 8068,\n",
       " 12543,\n",
       " 5687,\n",
       " 213,\n",
       " 15117,\n",
       " 7145,\n",
       " 1266,\n",
       " 10658,\n",
       " 14990,\n",
       " 2809,\n",
       " 12883,\n",
       " 3190,\n",
       " 9413,\n",
       " 11651,\n",
       " 9637,\n",
       " 3988,\n",
       " 2540,\n",
       " 10345,\n",
       " 14200,\n",
       " 14919,\n",
       " 7051,\n",
       " 2139,\n",
       " 8679,\n",
       " 5386,\n",
       " 197,\n",
       " 14123,\n",
       " 1526,\n",
       " 7436,\n",
       " 7608,\n",
       " 6187,\n",
       " 9141,\n",
       " 4084,\n",
       " 6497,\n",
       " 264,\n",
       " 3660,\n",
       " 1537,\n",
       " 6626,\n",
       " 3460,\n",
       " 541,\n",
       " 7710,\n",
       " 9903,\n",
       " 13894,\n",
       " 14629,\n",
       " 5586,\n",
       " 11763,\n",
       " 1916,\n",
       " 2745,\n",
       " 4822,\n",
       " 8538,\n",
       " 6901,\n",
       " 545,\n",
       " 171,\n",
       " 12614,\n",
       " 6518,\n",
       " 3238,\n",
       " 6098,\n",
       " 2122,\n",
       " 14606]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 100\n",
    "cos_s = np.asarray(cos_sim)\n",
    "cos_s.argsort()[-top_k -1 : -1][::-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아래는 메모리를 너무 많이 잡아먹어서 Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "embeddings_article = tf.get_variable(\"artcle_matrix\",initializer = article_total_matrix_1)\n",
    "norm_article = tf.sqrt(tf.reduce_sum(tf.square(embeddings_article),1,keep_dims =True))\n",
    "normalized_embeddings_article = embeddings_article / norm_article\n",
    "\n",
    "embeddings_user = tf.get_variable(\"user_matrix\",initializer = user_matrix_1)\n",
    "norm_user = tf.sqrt(tf.reduce_sum(tf.square(embeddings_user),1,keep_dims =True))\n",
    "normalized_embeddings_user = embeddings_user / norm_user\n",
    "\n",
    "\n",
    "similarity = tf.matmul(normalized_embeddings_user, normalized_embeddings_article, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    sim = similarity.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
